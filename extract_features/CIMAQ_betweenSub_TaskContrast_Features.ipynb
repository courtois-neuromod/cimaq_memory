{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates subject per voxel matrices to be used as features in between-subject classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nilearn\n",
    "import scipy\n",
    "import nibabel\n",
    "\n",
    "from numpy import nan as NaN\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats.stats import pearsonr\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "from nilearn import datasets\n",
    "from nilearn.plotting import plot_stat_map, plot_roi, plot_anat, plot_img, show\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.connectome import ConnectivityMeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Create group mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 1)\n",
      "Int64Index([108391, 120839, 122922, 127228, 139593, 147863, 150649, 164965,\n",
      "            175295, 178101, 189005, 197192, 199801, 219637, 229301, 247659,\n",
      "            254402, 255499, 258618, 258912, 267168, 270218, 271596, 314409,\n",
      "            326073, 336665, 337021, 350555, 370092, 385370, 386333, 396250,\n",
      "            403131, 408506, 413474, 427357, 437101, 439776, 441008, 458807,\n",
      "            459801, 462345, 484204, 490035, 502616, 517070, 520377, 543589,\n",
      "            549994, 555537, 567214, 597569, 619278, 628299, 630120, 652850,\n",
      "            658178, 659068, 668786, 677561, 711830, 729722, 739694, 748676,\n",
      "            763590, 778749, 783781, 785217, 785245, 804743, 845675, 866812,\n",
      "            878354, 884343, 886007, 893978, 901551, 906145, 914042, 915022,\n",
      "            920577, 932933, 936730, 938001, 955548, 956049, 956130, 968913,\n",
      "            974246, 979001, 983291, 988602, 996599, 998166],\n",
      "           dtype='int64', name='sub_ids')\n"
     ]
    }
   ],
   "source": [
    "# Load list of participants to include\n",
    "s_list = '/Users/mombot/Documents/Simexp/CIMAQ/Data/Participants/sub_list_TaskQC.tsv'\n",
    "slist = pd.read_csv(s_list, sep = '\\t')\n",
    "print(slist.shape)\n",
    "slist.set_index('sub_ids', inplace=True)\n",
    "ids = slist.index\n",
    "print(ids)\n",
    "\n",
    "##Steps to create group mask here\n",
    "\n",
    "#mask = mask \n",
    "\n",
    "\n",
    "# Mask images with group mask first? Can it concatenate images if number of vox differs per subject?\n",
    "\n",
    "\n",
    "# for each contrast between conditions, load beta maps (one per subject, id in increasing order)\n",
    "# Correct vs Incorrect Source\n",
    "betas_cs_minus_ws = image.load_img(img='/Users/mombot/Documents/Simexp/CIMAQ/Data/test/testOut/Output/Betas/*/TaskContrasts/betas_sub*_cs_minus_ws.nii',\n",
    "                           wildcards=True)\n",
    "\n",
    "print(betas_cs_minus_ws.header.get_data_shape()) #shape of 4D betas map image object\n",
    "print(betas_cs_minus_ws.header.get_zooms()) #voxel sizes in mm\n",
    "\n",
    "\n",
    "\n",
    "#IMPORTANT: REMOVE SUBJECTS WHO DO NOT HAVE ANY TRIALS FROM EITHER CONDITION!!\n",
    "\n",
    "# Other contrasts of interest:\n",
    "#Encoding vs Control Condition\n",
    "betas_enc_minus_ctl = image.load_img(img='/Users/mombot/Documents/Simexp/CIMAQ/Data/test/testOut/Output/Betas/*/TaskContrasts/betas_sub*_enc_minus_ctl.nii',\n",
    "                           wildcards=True)\n",
    "\n",
    "# Hit vs Miss\n",
    "betas_hit_minus_miss = image.load_img(img='/Users/mombot/Documents/Simexp/CIMAQ/Data/test/testOut/Output/Betas/*/TaskContrasts/betas_sub*_hit_minus_miss.nii',\n",
    "                           wildcards=True)\n",
    "\n",
    "# Hit vs Control Condition\n",
    "betas_hit_minus_ctl = image.load_img(img='/Users/mombot/Documents/Simexp/CIMAQ/Data/test/testOut/Output/Betas/*/TaskContrasts/betas_sub*_hit_minus_ctl.nii',\n",
    "                           wildcards=True)\n",
    "\n",
    "# Correct Source vs Miss\n",
    "betas_cs_minus_miss = image.load_img(img='/Users/mombot/Documents/Simexp/CIMAQ/Data/test/testOut/Output/Betas/*/TaskContrasts/betas_sub*_cs_minus_miss.nii',\n",
    "                           wildcards=True)\n",
    "\n",
    "# Correct Source vs Control Condition\n",
    "betas_cs_minus_ctl = image.load_img(img='/Users/mombot/Documents/Simexp/CIMAQ/Data/test/testOut/Output/Betas/*/TaskContrasts/betas_sub*_cs_minus_ctl.nii',\n",
    "                           wildcards=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use NiftiMasker object to convert epi images into a frames x voxels data matrix (310 x 69924)\n",
    "masker = NiftiMasker(mask_img=mask, standardize=True)\n",
    "\n",
    "cs_minus_ws = masker.fit_transform(betas_cs_minus_ws)\n",
    "\n",
    "print(cs_minus_ws.shape) \n",
    "\n",
    "enc_minus_ctl = masker.fit_transform(betas_enc_minus_ctl)\n",
    "hit_minus_miss = masker.fit_transform(betas_hit_minus_miss)\n",
    "hit_minus_ctl = masker.fit_transform(betas_hit_minus_ctl)\n",
    "cs_minus_miss = masker.fit_transform(betas_cs_minus_miss)\n",
    "cs_minus_ctl = masker.fit_transform(betas_cs_minus_ctl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latent memory score\n",
    "\n",
    "npsych_data = '/Users/mombot/Documents/Simexp/CIMAQ/Data/Participants/SubjectList.tsv'\n",
    "neuropsych = pd.read_csv(npsych_data, sep = '\\t')\n",
    "\n",
    "neuropsych.set_index('participant_id', inplace=True)\n",
    "neuropsych = neuropsych[neuropsych['QC_status'] is not 'F']\n",
    "# neuropsych = neuropsych[neuropsych['QC_status'] != 'F']\n",
    "\n",
    "# Latent memory score per participant\n",
    "memoscore = neuropsych['Fac1_memory']\n",
    "\n",
    "# Participant diagnosis \n",
    "status = neuropsych['cognitive_status']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
