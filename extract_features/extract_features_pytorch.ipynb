{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b7da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nii2png\n",
    "import os\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "from cimaq_utils import absoluteFilePaths, str_inc, seq_eve, seq_odd \n",
    "\n",
    "fmriprep_dir = '/data/simexp/cimaq_preproc/fmriprep/'\n",
    "events_dir = '/data/simexp/CIMAQ_AS_BIDS/'\n",
    "atlases_dir = '../../nilearn_atlases/'\n",
    "task, space, mdlt = 'memory', 'MNI152NLin2009cAsym', 'T1w'\n",
    "\n",
    "anat_suffix = f'*_space-{space}_desc-preproc_{mdlt}.nii.gz'\n",
    "bold_suffix = f'_task-{task}_space-{space}_desc-preproc_bold.nii.gz'\n",
    "mask_suffix = f'_task-{task}_space-{space}_desc-brain_mask.nii.gz'\n",
    "\n",
    "sub_ids = list(next(os.walk(fmriprep_dir)))[1]\n",
    "sub_ids\n",
    "fmri_paths = '\\n'.join(sorted(str_inc([bold_suffix],\n",
    "                                      list(absoluteFilePaths(fmriprep_dir)))))\n",
    "fmri_paths.splitlines()[0]\n",
    "# Path('/data/simexp/fnadeau/memory_bold_files.txt').write_text(fmri_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46fa00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('/data/simexp/fnadeau/cimaq_2d/')\n",
    "# 'nhtlnbrlk.gg.nii.xz'.rsplit('.')\n",
    "# v=180\n",
    "\n",
    "# import nibabel\n",
    "# from nilearn.image import load_img\n",
    "# rot904d = lambda arr, x, z: numpy.rot90(arr[:, :, x, z])\n",
    "# image_array = load_img(path00).get_data()\n",
    "# rot904d(image_array)\n",
    "divmod(270,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1005709",
   "metadata": {},
   "outputs": [],
   "source": [
    "path00='/data/simexp/fnadeau/cimaq_2d/sub-3002498/ses-V10/func/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'\n",
    "# path00 = Path(path00)\n",
    "# # dir(path00)\n",
    "# # path00.split(path00.suffixes[0])[0]\n",
    "# justname = str(path00).rstrip(''.join(path00.suffixes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa52d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fmriprep_mask(fmri_path:Union[str,os.PathLike],\n",
    "                      mask_ext:str='nii.gz', **kwargs):\n",
    "    bids_patt = lambda p: f'(?<={p})[a-zA-Z0-9]*'\n",
    "    prefixes = ['sub-','ses-','task-','space-']\n",
    "    mask_sfx = '_'.join([pf+re.search(bids_patt(pf),\n",
    "                                      os.path.basename(fmri_path)).group()\n",
    "                         for pf in prefixes]+[f'desc-brain_mask.{mask_ext}'])\n",
    "    return glob.glob(os.path.join(os.path.dirname(fmri_path), mask_sfx))[0]\n",
    "\n",
    "def get_fmriprep_anat(fmri_path:Union[str,os.PathLike],\n",
    "                      mdlt:str='T1w', ext:str='nii.gz',\n",
    "                      **kwargs):\n",
    "    space = '_space-'+re.search(f'(?<=_space-)[a-zA-Z0-9]*',\n",
    "                      os.path.basename(fmri_path)).group()\n",
    "    anat_suffix = f'*{space}_desc-preproc_{mdlt}.{ext}'\n",
    "    return str(next(list(Path(fmri_path).parents)[2].rglob(anat_suffix)))\n",
    "\n",
    "def get_events(fmri_path:Union[str,os.PathLike],\n",
    "               events_dir:Union[str,os.PathLike])->str:\n",
    "    sub_id, ses_id = Path(fmri_path).parts[-4:-2]\n",
    "    globbed = glob.glob(os.path.join(events_dir,\n",
    "                                  *Path(fmri_path).parts[-4:-2],\n",
    "                                  '*events.tsv'))\n",
    "    return [False if globbed == [] else globbed[0]][0]\n",
    "\n",
    "        \n",
    "def fetch_fmriprep_session(fmri_path:Union[str,os.PathLike],\n",
    "                           events_dir:Union[str,os.PathLike],\n",
    "                           strategy:str='Minimal',\n",
    "                           anat_mod:str='T1w',\n",
    "                           lc_kws:dict=None,\n",
    "                           clean_kws:dict=None,\n",
    "                           **kwargs):\n",
    "    import load_confounds\n",
    "    from inspect import getmembers\n",
    "    from sklearn.utils import Bunch\n",
    "    from pathlib import Path\n",
    "    sub_id, ses_id = Path(fmri_path).parts[-4:-2]\n",
    "    mask_path = get_fmriprep_mask(fmri_path)\n",
    "    anat_path = get_fmriprep_anat(fmri_path)\n",
    "    loader = dict(getmembers(load_confounds))[f'{strategy}']\n",
    "    loader = [loader(**lc_kws) if lc_kws is not None\n",
    "              else loader()][0]    \n",
    "    event_path = get_events(fmri_path,events_dir)\n",
    "    if event_path is False:\n",
    "        return False\n",
    "    else:\n",
    "        return Bunch(**dict(sub_id=sub_id, ses_id=ses_id,\n",
    "                            full_mask_path=mask_path,\n",
    "                            fmri_path=fmri_path,\n",
    "                            anat_path=anat_path,\n",
    "                            event_path=event_path,\n",
    "                            loader=loader,\n",
    "                            confounds_strategy=strategy))\n",
    "\n",
    "def load_fmriprep_session(fmri_path:Union[str,os.PathLike],\n",
    "                          events_dir:Union[str,os.PathLike],\n",
    "                          clean_kws:dict=None,\n",
    "                          masker_kws:dict=None,\n",
    "                          **kwargs):\n",
    "    from nilearn import image as nimage\n",
    "    from nilearn.masking import apply_mask, unmask\n",
    "    from nilearn.signal import clean\n",
    "    from sklearn.utils import Bunch\n",
    "    from glob import glob\n",
    "    from nilearn import image as nimage\n",
    "    session = fetch_fmriprep_session(fmri_path,events_dir)\n",
    "    fmri_img, mask_img, anat_img = \\\n",
    "        tuple(map(nimage.load_img,[session.fmri_path, session.full_mask_path,\n",
    "                                   session.anat_path]))\n",
    "    t_r = fmri_img.header.get_zooms()[-1]\n",
    "    conf = session.loader.load(session.fmri_path)\n",
    "    clean_defs = dict(standardize=False,\n",
    "                      standardize_confounds=False,\n",
    "                      high_pass=None, low_pass=None,\n",
    "                      t_r=fmri_img.header.get_zooms()[-1],\n",
    "                      ensure_finite=True)\n",
    "    masker_defs = dict(mask_img=mask_img,\n",
    "                       allow_overlap=True, t_r=t_r,\n",
    "                       standardize_confounds=False,\n",
    "                       resampling_target='mask')\n",
    "    if masker_kws is not None:\n",
    "        masker_defs.update(masker_kws)\n",
    "    if clean_kws is not None:\n",
    "        clean_defs.update(clean_kws)\n",
    "    cleaned_fmri = unmask(clean(apply_mask(fmri_img, mask_img,\n",
    "                                           smoothing_fwhm=8,\n",
    "                                           dtype='f'),\n",
    "                                confounds=conf,\n",
    "                                **clean_defs),\n",
    "                          mask_img)\n",
    "    cleaned_fmri = nimage.new_img_like(fmri_img, cleaned_fmri.get_fdata(),\n",
    "                               copy_header=True)\n",
    "    events = pd.read_csv(session.event_path, sep='\\t').iloc[1:,:]\n",
    "    loaded = Bunch(**dict(fmri_img=fmri_img, cleaned_fmri=cleaned_fmri,\n",
    "                          full_mask_img=mask_img, anat_img=anat_img,\n",
    "                          clean_params=clean_defs, masker_params=masker_defs,\n",
    "                          confounds=conf, events=events, t_r=t_r))\n",
    "    loaded.update(session)\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def rot90flip(data, rot_angle:int=None, scl, vol):\n",
    "    \n",
    "rot90flip=lambda a, s, v: np.rot90(a[:,:,s,v])\n",
    "rot180flip=lambda a, s, v: np.rot90(np.rot90(a[:,:,s,v]))\n",
    "rot270flip=lambda a, s, v: np.rot90(np.rot90(np.rot90(a[:,:,s,v])))\n",
    "rot_dict = {90: rot90flip, 180: rot180flip, 270: rot270flip}\n",
    "rot_dict[90]([0,1,2], 2, 3)\n",
    "# np.rot90([[0,1,2]][:, :, 2, 33])\n",
    "# import scipy\n",
    "# dir(scipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a88560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "980a9b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function repeat in module numpy:\n",
      "\n",
      "repeat(a, repeats, axis=None)\n",
      "    Repeat elements of an array.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    repeats : int or array of ints\n",
      "        The number of repetitions for each element.  `repeats` is broadcasted\n",
      "        to fit the shape of the given axis.\n",
      "    axis : int, optional\n",
      "        The axis along which to repeat values.  By default, use the\n",
      "        flattened input array, and return a flat output array.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    repeated_array : ndarray\n",
      "        Output array which has the same shape as `a`, except along\n",
      "        the given axis.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    tile : Tile an array.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.repeat(3, 4)\n",
      "    array([3, 3, 3, 3])\n",
      "    >>> x = np.array([[1,2],[3,4]])\n",
      "    >>> np.repeat(x, 2)\n",
      "    array([1, 1, 2, 2, 3, 3, 4, 4])\n",
      "    >>> np.repeat(x, 3, axis=1)\n",
      "    array([[1, 1, 1, 2, 2, 2],\n",
      "           [3, 3, 3, 4, 4, 4]])\n",
      "    >>> np.repeat(x, [1, 2], axis=0)\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [3, 4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# src = '../../flat_bold_png/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold_t306_z46.png'\n",
    "\n",
    "\n",
    "# imageio.imread(src).shape\n",
    "help(np.repeat)\n",
    "\n",
    "# Image.open(src)._Image__transformer()\n",
    "# dir(img._Image__transformer)\n",
    "# skimage.show(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77e182c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "cimaq_stims = list(map(str, list(Path('../../WMStim').rglob('*.bmp'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "45b794fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "          ...,\n",
       "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
       "\n",
       "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "          ...,\n",
       "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
       "\n",
       "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "          ...,\n",
       "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_image(src:Union[str,os.PathLike]):\n",
    "    # Open image\n",
    "#     input_image = PIL.Image.fromarray(np.uint8(PIL.Image.open(src)))\n",
    "#     input_image = PIL.Image.fromarray(PIL.Image.open(src))\n",
    "    input_image = PIL.Image.open(src)\n",
    "    # Preprocess image\n",
    "    preprocess = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                          std=[0.229, 0.224, 0.225])])\n",
    "    return preprocess(input_image).unsqueeze(0)\n",
    "preprocess_image(cimaq_stims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b77d841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function imread in module imageio.core.functions:\n",
      "\n",
      "imread(uri, format=None, **kwargs)\n",
      "    imread(uri, format=None, **kwargs)\n",
      "    \n",
      "    Reads an image from the specified file. Returns a numpy array, which\n",
      "    comes with a dict of meta data at its 'meta' attribute.\n",
      "    \n",
      "    Note that the image data is returned as-is, and may not always have\n",
      "    a dtype of uint8 (and thus may differ from what e.g. PIL returns).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    uri : {str, pathlib.Path, bytes, file}\n",
      "        The resource to load the image from, e.g. a filename, pathlib.Path,\n",
      "        http address or file object, see the docs for more info.\n",
      "    format : str\n",
      "        The format to use to read the file. By default imageio selects\n",
      "        the appropriate for you based on the filename and its contents.\n",
      "    kwargs : ...\n",
      "        Further keyword arguments are passed to the reader. See :func:`.help`\n",
      "        to see what arguments are available for a particular format.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(imageio.imread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c576dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../WMStim/Kitchen_apron.bmp',\n",
       " '../../WMStim/animal_camel_new.bmp',\n",
       " '../../WMStim/animal_cheetah.bmp',\n",
       " '../../WMStim/animal_chimpanzee.bmp',\n",
       " '../../WMStim/animal_dalmation_old.bmp',\n",
       " '../../WMStim/animal_dolphin_old.bmp',\n",
       " '../../WMStim/animal_farm pig.bmp',\n",
       " '../../WMStim/animal_frog.bmp',\n",
       " '../../WMStim/animal_giraffe.bmp',\n",
       " '../../WMStim/animal_gorilla.bmp',\n",
       " '../../WMStim/animal_hen.bmp',\n",
       " '../../WMStim/animal_hippo_new.bmp',\n",
       " '../../WMStim/animal_horse.bmp',\n",
       " '../../WMStim/animal_lion_new.bmp',\n",
       " '../../WMStim/animal_monarch_old.bmp',\n",
       " '../../WMStim/animal_mouse.bmp',\n",
       " '../../WMStim/animal_ostrich.bmp',\n",
       " '../../WMStim/animal_parrot.bmp',\n",
       " '../../WMStim/animal_penguin.bmp',\n",
       " '../../WMStim/animal_pigeon.bmp',\n",
       " '../../WMStim/animal_polar bear_old.bmp',\n",
       " '../../WMStim/animal_seal.bmp',\n",
       " '../../WMStim/animal_sheep.bmp',\n",
       " '../../WMStim/animal_siamese cat.bmp',\n",
       " '../../WMStim/animal_tortoise.bmp',\n",
       " '../../WMStim/animal_white tiger.bmp',\n",
       " '../../WMStim/animal_zebra_old.bmp',\n",
       " '../../WMStim/black.bmp',\n",
       " '../../WMStim/food_almond.bmp',\n",
       " '../../WMStim/food_bagel01.bmp',\n",
       " '../../WMStim/food_baguette01.bmp',\n",
       " '../../WMStim/food_bottleofredwine01.bmp',\n",
       " '../../WMStim/food_bread.bmp',\n",
       " '../../WMStim/food_candy.bmp',\n",
       " '../../WMStim/food_champagne.bmp',\n",
       " '../../WMStim/food_chocolatemilk.bmp',\n",
       " '../../WMStim/food_cookie01.bmp',\n",
       " '../../WMStim/food_cracker02.bmp',\n",
       " '../../WMStim/food_croissant01.bmp',\n",
       " '../../WMStim/food_drink.bmp',\n",
       " '../../WMStim/food_egg01a.bmp',\n",
       " '../../WMStim/food_frenchfries.bmp',\n",
       " '../../WMStim/food_icecreamcone01a.bmp',\n",
       " '../../WMStim/food_pecan02.bmp',\n",
       " '../../WMStim/food_pickle01a.bmp',\n",
       " '../../WMStim/food_pizza.bmp',\n",
       " '../../WMStim/food_rawchicken.bmp',\n",
       " '../../WMStim/food_rice.bmp',\n",
       " '../../WMStim/food_sausage.bmp',\n",
       " '../../WMStim/food_shellpasta.bmp',\n",
       " '../../WMStim/food_softcheese.bmp',\n",
       " '../../WMStim/food_toast.bmp',\n",
       " '../../WMStim/food_walnut01c.bmp',\n",
       " '../../WMStim/fruit_apricot_new.bmp',\n",
       " '../../WMStim/fruit_banana_old.bmp',\n",
       " '../../WMStim/fruit_blackberry_new.bmp',\n",
       " '../../WMStim/fruit_blueberry.bmp',\n",
       " '../../WMStim/fruit_cherry.bmp',\n",
       " '../../WMStim/fruit_granny smith apple.bmp',\n",
       " '../../WMStim/fruit_green grapes.bmp',\n",
       " '../../WMStim/fruit_lemon_new.bmp',\n",
       " '../../WMStim/fruit_pear.bmp',\n",
       " '../../WMStim/fruit_pineapple_old.bmp',\n",
       " '../../WMStim/fruit_rasberry.bmp',\n",
       " '../../WMStim/fruit_tomato.bmp',\n",
       " '../../WMStim/fruit_watermelon_old.bmp',\n",
       " '../../WMStim/hard_musical_recorder.bmp',\n",
       " '../../WMStim/kitchen_baking spatula.bmp',\n",
       " '../../WMStim/kitchen_big cooking pot.bmp',\n",
       " '../../WMStim/kitchen_bowl.bmp',\n",
       " '../../WMStim/kitchen_coffee pot.bmp',\n",
       " '../../WMStim/kitchen_cookie cutter.bmp',\n",
       " '../../WMStim/kitchen_dishwashing liquid.bmp',\n",
       " '../../WMStim/kitchen_fork_old.bmp',\n",
       " '../../WMStim/kitchen_frying pan_old.bmp',\n",
       " '../../WMStim/kitchen_garlic press.bmp',\n",
       " '../../WMStim/kitchen_kettle_new.bmp',\n",
       " '../../WMStim/kitchen_ladle.bmp',\n",
       " '../../WMStim/kitchen_martini glass.bmp',\n",
       " '../../WMStim/kitchen_mug.bmp',\n",
       " '../../WMStim/kitchen_peppermill.bmp',\n",
       " '../../WMStim/kitchen_pitcher.bmp',\n",
       " '../../WMStim/kitchen_plate.bmp',\n",
       " '../../WMStim/kitchen_ramekin.bmp',\n",
       " '../../WMStim/kitchen_rolling pin_new.bmp',\n",
       " '../../WMStim/kitchen_scrubbing brush.bmp',\n",
       " '../../WMStim/kitchen_sharp knife.bmp',\n",
       " '../../WMStim/kitchen_spatula_old.bmp',\n",
       " '../../WMStim/kitchen_tea cup and saucer.bmp',\n",
       " '../../WMStim/kitchen_toaster_old.bmp',\n",
       " '../../WMStim/kitchen_white strainer.bmp',\n",
       " '../../WMStim/kitchen_wine glass.bmp',\n",
       " '../../WMStim/kitchen_wooden spoon_old.bmp',\n",
       " '../../WMStim/mach_bands.bmp',\n",
       " '../../WMStim/musical_accordion_old.bmp',\n",
       " '../../WMStim/musical_acoustic guitar_new.bmp',\n",
       " '../../WMStim/musical_bagpipes.bmp',\n",
       " '../../WMStim/musical_banjo.bmp',\n",
       " '../../WMStim/musical_bongo drum.bmp',\n",
       " '../../WMStim/musical_clarinet_new.bmp',\n",
       " '../../WMStim/musical_double bass.bmp',\n",
       " '../../WMStim/musical_drums_old.bmp',\n",
       " '../../WMStim/musical_electric guitar_old.bmp',\n",
       " '../../WMStim/musical_flugelhorn.bmp',\n",
       " '../../WMStim/musical_french horn_old.bmp',\n",
       " '../../WMStim/musical_harmonica_new.bmp',\n",
       " '../../WMStim/musical_harp_new.bmp',\n",
       " '../../WMStim/musical_keyboard_new.bmp',\n",
       " '../../WMStim/musical_piano_old.bmp',\n",
       " '../../WMStim/musical_saxophone_new.bmp',\n",
       " '../../WMStim/musical_tambourine_new.bmp',\n",
       " '../../WMStim/musical_triangle.bmp',\n",
       " '../../WMStim/musical_trombone.bmp',\n",
       " '../../WMStim/musical_tuba.bmp',\n",
       " '../../WMStim/musical_uculele_new.bmp',\n",
       " '../../WMStim/musical_violin_old.bmp',\n",
       " '../../WMStim/musical_xylophone_old.bmp',\n",
       " '../../WMStim/musical_zamponia windflute.bmp',\n",
       " '../../WMStim/sporting_Badminton Racquet.bmp',\n",
       " '../../WMStim/sporting_americanfootball.bmp',\n",
       " '../../WMStim/sporting_baseball bat_new.bmp',\n",
       " '../../WMStim/sporting_baseball_old.bmp',\n",
       " '../../WMStim/sporting_basketball_new.bmp',\n",
       " '../../WMStim/sporting_bicycle_old.bmp',\n",
       " '../../WMStim/sporting_boxing_gloves.bmp',\n",
       " '../../WMStim/sporting_fishing rod.bmp',\n",
       " '../../WMStim/sporting_flippers.bmp',\n",
       " '../../WMStim/sporting_footballhelmet.bmp',\n",
       " '../../WMStim/sporting_golf ball.bmp',\n",
       " '../../WMStim/sporting_hockey stick_old.bmp',\n",
       " '../../WMStim/sporting_ice skate_old.bmp',\n",
       " '../../WMStim/sporting_karate clothing.bmp',\n",
       " '../../WMStim/sporting_lifejacket_new.bmp',\n",
       " '../../WMStim/sporting_mini-trampoline.bmp',\n",
       " '../../WMStim/sporting_pingpong.bmp',\n",
       " '../../WMStim/sporting_racquetball racket_old.bmp',\n",
       " '../../WMStim/sporting_rollerblade.bmp',\n",
       " '../../WMStim/sporting_skipping rope.bmp',\n",
       " '../../WMStim/sporting_snow shoes_old.bmp',\n",
       " '../../WMStim/sporting_soccer ball_new.bmp',\n",
       " '../../WMStim/sporting_softball mit.bmp',\n",
       " '../../WMStim/sporting_weighlifting.bmp',\n",
       " '../../WMStim/sporting_windsurf.bmp',\n",
       " '../../WMStim/vegie_broccoli.bmp',\n",
       " '../../WMStim/vegie_carrot.bmp',\n",
       " '../../WMStim/vegie_cauliflower.bmp',\n",
       " '../../WMStim/vegie_corn02.bmp',\n",
       " '../../WMStim/vegie_cucumber.bmp',\n",
       " '../../WMStim/vegie_garlic01a.bmp',\n",
       " '../../WMStim/vegie_green capsicum.bmp',\n",
       " '../../WMStim/vegie_lettuce.bmp',\n",
       " '../../WMStim/vegie_mushroom.bmp',\n",
       " '../../WMStim/vegie_pumpkin.bmp',\n",
       " '../../WMStim/vegie_radish.bmp',\n",
       " '../../WMStim/vegie_redonion.bmp',\n",
       " '../../WMStim/vegie_snowpea01.bmp']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(list(filter(lambda x: x.endswith('.bmp'), cimaq_stims)))==len(cimaq_stims)\n",
    "sorted(cimaq_stims)[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83a287f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for googlenet\n"
     ]
    }
   ],
   "source": [
    "model = GoogLeNet.from_pretrained(\"googlenet\")\n",
    "\n",
    "def get_features(src, model):\n",
    "#     input_tensor = preprocess_image(src)\n",
    "#     model.eval()\n",
    "    return model.extract_features(preprocess_image(src))\n",
    "features = [get_features(src, model) for src in sorted(cimaq_stims)[6:]]\n",
    "labels = list(map(os.path.basename, sorted(cimaq_stims)[6:]))\n",
    "# list(get_features(cimaq_stims[x], model) for x in range(len(cimaq_stims)))\n",
    "# help(model.eval)\n",
    "# eval mode shape == torch.Size([1, 1024, 7, 7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc902a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for googlenet\n",
      "torch.Size([1, 1024, 7, 7])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "eval() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52369/589093125.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#             print(f\"{label:<75} ({prob * 100:.2f}%)\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mtest_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcimaq_stims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_52369/589093125.py\u001b[0m in \u001b[0;36mload_inputs\u001b[0;34m(src)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Classify with GoogLeNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# move the input and model to GPU for speed if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: eval() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "apath = '../../flat_bold_png/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold_t306_z46.png'\n",
    "from googlenet_pytorch import GoogLeNet\n",
    "from typing import Union\n",
    "# model = GoogLeNet.from_pretrained(\"ImageNet\")\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import skimage\n",
    "import imageio\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from googlenet_pytorch import GoogLeNet \n",
    "\n",
    "\n",
    "def load_inputs(src:Union[str,os.PathLike]):\n",
    "    # Open image\n",
    "#     input_image = PIL.Image.open(BytesIO(imageio.imread(src)))\n",
    "#     model = VGG16()\n",
    "    model = GoogLeNet.from_pretrained(\"googlenet\")\n",
    "    input_image = PIL.Image.fromarray(np.stack(np.repeat(np.uint8(PIL.Image.open(src)),3, axis=0)))\n",
    "    # Preprocess image\n",
    "    preprocess = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                          std=[0.229, 0.224, 0.225])])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # create a mini-batch as expected by the model\n",
    "\n",
    "    # Load class names\n",
    "#     labels_map = json.load(open(\"labels_map.txt\"))\n",
    "#     labels_map = [labels_map[str(i)] for i in range(1000)]\n",
    "\n",
    "    # Feature extraction\n",
    "    # ... image preprocessing as in the classification example ...\n",
    "    # inputs = torch.randn(1, 3, 224, 224)\n",
    "#     print(inputs.shape) # torch.Size([1, 3, 224, 224])\n",
    "\n",
    "    features = model.extract_features(input_batch)\n",
    "    print(features.shape) # torch.Size([1, 1024, 7, 7])\n",
    "\n",
    "    # Classify with GoogLeNet\n",
    "    model.eval()\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to(\"cuda\")\n",
    "        model.to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_batch)\n",
    "        preds = torch.topk(logits, k=5).indices.squeeze(0).tolist()\n",
    "        print(\"-----\")\n",
    "        print(f'Predictions: {preds}')\n",
    "        for idx in preds:\n",
    "#             label = labels_map[idx]\n",
    "            prob = torch.softmax(logits, dim=1)[0, idx].item()\n",
    "#             print(f\"{label:<75} ({prob * 100:.2f}%)\")\n",
    "    return input_tensor, input_batch, features, prob\n",
    "test_tensors, test_batch, test_features, test_prob = load_inputs(cimaq_stims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d5b8d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006411508657038212"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48ec8c62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "model_name should be one of: googlenet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31376/743799827.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgooglenet_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogLeNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogLeNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ImageNet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mapath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../../flat_bold_png/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold_t306_z46.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/googlenet_pytorch/model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_name, num_classes)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverride_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"num_classes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mload_pretrained_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_fc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/googlenet_pytorch/model.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, model_name, override_params)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverride_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_model_name_is_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mglobal_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverride_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/googlenet_pytorch/model.py\u001b[0m in \u001b[0;36m_check_model_name_is_valid\u001b[0;34m(cls, model_name)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mvalid_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'googlenet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_name should be one of: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: model_name should be one of: googlenet"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from googlenet_pytorch import GoogLeNet\n",
    "from numpy import asarray\n",
    "model = GoogLeNet.from_pretrained('ImageNet')\n",
    "apath = '../../flat_bold_png/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold_t306_z46.png'\n",
    "from typing import Union\n",
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from googlenet_pytorch import GoogLeNet \n",
    "# ... image preprocessing as in the classification example ...\n",
    "# inputs = torch.randn(1, 3, 224, 224)\n",
    "# inputs = sorted(map(str,list(Path(testsess).iterdir())))\n",
    "# input_image = asarray(Image.open(apath))\n",
    "preprocess = transforms.Compose([transforms.Resize(256),\n",
    "                                 transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                      std=[0.229, 0.224, 0.225])])\n",
    "input_tensor = preprocess(Image.open(apath))\n",
    "print(input_tensor.shape) # torch.Size([1, 3, 224, 224])\n",
    "\n",
    "features = model.extract_features(input_tensor)\n",
    "torch.Size([1, 1024, 7, 7])\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d46edd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_Image__transformer',\n",
       " '_PngImageFile__prepare_idat',\n",
       " '__array_interface__',\n",
       " '__class__',\n",
       " '__copy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_close_exclusive_fp_after_loading',\n",
       " '_copy',\n",
       " '_crop',\n",
       " '_dump',\n",
       " '_ensure_mutable',\n",
       " '_exclusive_fp',\n",
       " '_exif',\n",
       " '_expand',\n",
       " '_get_safe_box',\n",
       " '_getexif',\n",
       " '_min_frame',\n",
       " '_new',\n",
       " '_open',\n",
       " '_repr_png_',\n",
       " '_seek_check',\n",
       " '_size',\n",
       " '_text',\n",
       " 'alpha_composite',\n",
       " 'category',\n",
       " 'close',\n",
       " 'convert',\n",
       " 'copy',\n",
       " 'crop',\n",
       " 'custom_mimetype',\n",
       " 'decoderconfig',\n",
       " 'decodermaxblock',\n",
       " 'draft',\n",
       " 'effect_spread',\n",
       " 'entropy',\n",
       " 'filename',\n",
       " 'filter',\n",
       " 'format',\n",
       " 'format_description',\n",
       " 'fp',\n",
       " 'frombytes',\n",
       " 'fromstring',\n",
       " 'get_format_mimetype',\n",
       " 'getbands',\n",
       " 'getbbox',\n",
       " 'getchannel',\n",
       " 'getcolors',\n",
       " 'getdata',\n",
       " 'getexif',\n",
       " 'getextrema',\n",
       " 'getim',\n",
       " 'getpalette',\n",
       " 'getpixel',\n",
       " 'getprojection',\n",
       " 'height',\n",
       " 'histogram',\n",
       " 'im',\n",
       " 'info',\n",
       " 'load',\n",
       " 'load_end',\n",
       " 'load_prepare',\n",
       " 'load_read',\n",
       " 'mode',\n",
       " 'offset',\n",
       " 'palette',\n",
       " 'paste',\n",
       " 'png',\n",
       " 'point',\n",
       " 'putalpha',\n",
       " 'putdata',\n",
       " 'putpalette',\n",
       " 'putpixel',\n",
       " 'pyaccess',\n",
       " 'quantize',\n",
       " 'readonly',\n",
       " 'reduce',\n",
       " 'remap_palette',\n",
       " 'resize',\n",
       " 'rotate',\n",
       " 'save',\n",
       " 'seek',\n",
       " 'show',\n",
       " 'size',\n",
       " 'split',\n",
       " 'tell',\n",
       " 'text',\n",
       " 'thumbnail',\n",
       " 'tile',\n",
       " 'tobitmap',\n",
       " 'tobytes',\n",
       " 'toqimage',\n",
       " 'toqpixmap',\n",
       " 'tostring',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'verify',\n",
       " 'width']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(Image.open(apath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7facb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c631cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlenet_pytorch import GoogLeNet\n",
    "model = GoogLeNet.from_pretrained(\"googlenet\")\n",
    "\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from googlenet_pytorch import GoogLeNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6111664",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U IProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7966b73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/simexp/fnadeau/cimaq_memory/extract_features'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56801597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18600"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('sub-3163875_ses-V03_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29772374",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatdir = '../../flat_bold_png/'\n",
    "from itertools import starmap\n",
    "from pathlib import Path\n",
    "testsess = sorted(Path(flatdir).iterdir())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ca3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca36129b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../flat_bold_png/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold_t306_z46.png'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(list(Path(testsess).iterdir())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684637a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
