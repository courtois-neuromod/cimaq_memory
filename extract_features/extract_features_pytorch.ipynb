{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0272b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nii2png\n",
    "import os\n",
    "from pathlib import Path\n",
    "from nibabel.nifti1 import Nifti1Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "from sklearn.utils import Bunch\n",
    "from typing import Union\n",
    "\n",
    "from cimaq_decoding_utils import fetch_cimaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b7da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fmriprep_dir = '/data/simexp/cimaq_preproc/fmriprep/'\n",
    "events_dir = '/data/simexp/CIMAQ_AS_BIDS/'\n",
    "atlases_dir = '../../nilearn_atlases/'\n",
    "\n",
    "\n",
    "\n",
    "subjects = fetch_cimaq(topdir=fmriprep_dir, events_dir=events_dir, n_ses=2).data\n",
    "sub00, sub01 = tuple(subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5d777e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_fmri(fmri_path:Union[str,os.PathLike, Nifti1Image],\n",
    "               events_path:Union[str,os.PathLike, pd.DataFrame],\n",
    "               sep:str='\\t', t_r:float=None,\n",
    "               **kwargs):\n",
    "    from itertools import starmap\n",
    "    from more_itertools import flatten\n",
    "    from nilearn import image as nimage\n",
    "    import pandas as pd\n",
    "    # Make pandas Intervals (b:list of beginnigs, e:list of ends)\n",
    "    mkintrvls = lambda b, e: list(starmap(pd.Interval,tuple(zip(b, e))))\n",
    "    fmri_img = nimage.load_img(fmri_path)\n",
    "    if not isinstance(events_path, pd.DataFrame):\n",
    "        events = pd.read_csv(events_path, sep=sep)\n",
    "    else:\n",
    "        events = events_path\n",
    "    t_r = [t_r if t_r is not None else\n",
    "           fmri_img.header.get_zooms()[-1]][0]\n",
    "    frame_times = np.arange(fmri_img.shape[-1]) * t_r\n",
    "    frame_ends = pd.Series(frame_times).add(t_r).values\n",
    "    frame_intervals = mkintrvls(pd.Series(frame_times).values,\n",
    "                                frame_ends)\n",
    "    trial_ends=(events.onset+abs(events.onset -\n",
    "                                 events.offset)+events.isi).values\n",
    "    trial_intervals = mkintrvls(events.onset.values, trial_ends)\n",
    "    valid_trial_idx = [trial[0] for trial in enumerate(trial_intervals)\n",
    "                       if trial[1].left<frame_intervals[-1].left]\n",
    "    valid_trials = pd.Series(trial_intervals).loc[valid_trial_idx].values\n",
    "#     trial_intervals = list(starmap(pd.Interval,tuple(zip(events.onset.values, trial_ends))))\n",
    "    bold_by_trial_indx = [[frame[0] for frame in enumerate(frame_intervals)\n",
    "                           if frame[1].left in trial] for trial in valid_trials]\n",
    "    bold_by_trial = list(nimage.index_img(fmri_img, idx)\n",
    "                         for idx in bold_by_trial_indx)\n",
    "    valid_frame_intervals = [pd.Series(frame_intervals).loc[bold_idx].values\n",
    "                             for bold_idx in bold_by_trial_indx]\n",
    "    perfo_labels = events.iloc[valid_trial_idx].recognition_performance.fillna('Ctl')\n",
    "    condition_labels = events.iloc[valid_trial_idx].trial_type\n",
    "    stim_labels = events.iloc[valid_trial_idx].stim_file.fillna('Ctl').values\n",
    "    categ_labels = events.iloc[valid_trial_idx].stim_category.fillna('Ctl').values\n",
    "    return pd.DataFrame(tuple(zip(valid_trial_idx, bold_by_trial,\n",
    "                                  bold_by_trial_indx, valid_trials,\n",
    "                                  valid_frame_intervals, condition_labels,\n",
    "                                  perfo_labels, stim_labels, categ_labels)),\n",
    "                        columns=['trials', 'trial_niftis', 'fmri_frames',\n",
    "                                 'trial_intervals', 'fmri_frame_intervals',\n",
    "                                 'condition_labels', 'performance_labels',\n",
    "                                 'stimuli_files', 'category_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64693f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 77, 60, 310)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub00.cleaned_fmri.get_fdata().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0a084c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 93093000 into shape (77,60,117)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10871/1392968741.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestimg_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msub00\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleaned_fmri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m77\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m117\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# testimg_data.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 93093000 into shape (77,60,117)"
     ]
    }
   ],
   "source": [
    "testimg_data=sub00.cleaned_fmri.get_fdata().reshape(-1,77,60,117)\n",
    "# testimg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecfc88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiMapsMasker\n",
    "from sklearn.utils import Bunch\n",
    "from get_difumo import get_difumo\n",
    "atlases_dir = '../../nilearn_atlases/difumo_atlases/'\n",
    "#/difumo_atlases/256/3mm/maps.nii.gz'\n",
    "\n",
    "difumo_256 = get_difumo('../../nilearn_atlases/difumo_atlases/', 256, 3)\n",
    "\n",
    "sub00.mapsmasker = NiftiMapsMasker(difumo_256.maps, mask_img=sub00.mask_img,\n",
    "                                   resampling_target='mask',\n",
    "                                   allow_overlap=True, **sub00.masker_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53398a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub00.mapsmasker.fit(sub00.cleaned_fmri)\n",
    "sub00.maps_signals = sub00.mapsmasker.transform_single_imgs(sub00.cleaned_fmri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6927102c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 256)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub00.maps_signals.shape#reshape(117,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71573407",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The shape specified should be the shape of the 3D grid, and thus of length 3. (65, 77, 60, 117) was specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10871/2137298603.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                      \u001b[0mtarget_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                      \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                      clip=True, force_resample=True)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# testmean = nilearn.image.concat_imgs([nilearn.image.mean_img(trial)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#                            for trial in sub00.vectors.trial_niftis])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/nilearn/image/resampling.py\u001b[0m in \u001b[0;36mresample_img\u001b[0;34m(img, target_affine, target_shape, interpolation, copy, order, clip, fill_value, force_resample)\u001b[0m\n\u001b[1;32m    414\u001b[0m         raise ValueError('The shape specified should be the shape of '\n\u001b[1;32m    415\u001b[0m                          \u001b[0;34m'the 3D grid, and thus of length 3. %s was specified'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                          % str(target_shape))\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtarget_affine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The shape specified should be the shape of the 3D grid, and thus of length 3. (65, 77, 60, 117) was specified"
     ]
    }
   ],
   "source": [
    "import nilearn \n",
    "sub00.vectors = trial_fmri(sub00.cleaned_fmri, sub00.events)\n",
    "newshape=tuple(list(sub00.cleaned_fmri.shape)[:-1]+[117])\n",
    "testimg = nilearn.image.resample_img(sub00.cleaned_fmri,\n",
    "                                     target_affine=sub00.cleaned_fmri.affine,\n",
    "                                     target_shape=newshape,\n",
    "                                     interpolation='nearest',\n",
    "                                     clip=True, force_resample=True)\n",
    "# testmean = nilearn.image.concat_imgs([nilearn.image.mean_img(trial)\n",
    "#                            for trial in sub00.vectors.trial_niftis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub00.mapsmasker.fit(testmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4dcf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub00.events.stim_category.replace({'K':'kitchen'}).fillna('Ctl').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4201da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub00.mapsmasker_mean = NiftiMapsMasker(difumo_256.maps, mask_img=sub00.mask_img,\n",
    "#                                         resampling_target='mask',\n",
    "#                                         allow_overlap=True, **sub00.masker_defs)\n",
    "# sub00.mapsmasker_mean.fit(testmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c250af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub00.maps_mean_signals = sub00.mapsmasker.transform_single_imgs(testmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d36a14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sub00.behav.stim_category.replace({'K':'kitchen'}).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c3dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# sub_svc = sklearn.svm.NuSVC() # 0.68 avg acc up to now\n",
    "# sub_svc = sklearn.linear_model.SGDClassifier()\n",
    "# \n",
    "# Cross-validation within 10 folds of training set\n",
    "# predict\n",
    "# class_weight='balanced'\n",
    "cv_y_pred = cross_val_predict(sub_svc, X_train, y_train,\n",
    "                              groups=y_train, cv=10)\n",
    "# scores\n",
    "cv_acc = cross_val_score(sub_svc, X_train, y_train,\n",
    "                         groups=y_train, cv=10)\n",
    "print(f'Cross-validation accuracy: {cv_acc}')\n",
    "\n",
    "# evaluate overall model performance on training data\n",
    "overall_acc = accuracy_score(y_pred = cv_y_pred, y_true = y_train)\n",
    "overall_cr = classification_report(y_pred = cv_y_pred, y_true = y_train)\n",
    "print(f'Accuracy\\n{round(overall_acc, 3)}\\n\\nOverall Score\\n{overall_cr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub00.events.recognition_performance.values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size=0.4\n",
    "svc = LinearSVC(max_iter=100000)\n",
    "signals = sub00.maps_mean_signals\n",
    "# conditions = sub00.events.trial_type.values#.replace({'Enc':1,'Ctl':2}).values\n",
    "conditions = sub00.events.recognition_performance.fillna('Ctl').values\n",
    "# conditions = sub00.events.trial_type.replace({'Enc':'enc','Ctl':'ctl'}).astype('str')\n",
    "groups = sub00.behav.recognition_performance.fillna('Ctl').values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e8538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import it and define your fancy objects\n",
    "from sklearn.feature_selection import RFE\n",
    "svc = LinearSVC()\n",
    "rfe = RFE(SVC(kernel='linear', C=1.), n_features_to_select=117, step=0.25)\n",
    "\n",
    "# Create a new pipeline, composing the two classifiers `rfe` and `svc`\n",
    "\n",
    "rfe_svc = Pipeline([('rfe', rfe), ('svc', svc)])\n",
    "\n",
    "# Recompute the cross-validation score\n",
    "cv_scores = cross_val_score(rfe_svc, signals, target, cv=cv, n_jobs=-1, verbose=1)\n",
    "# But, be aware that this can take * A WHILE * ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d2ecab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1e-4<\n",
    "5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6609f1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LinearSVC in module sklearn.svm._classes:\n",
      "\n",
      "class LinearSVC(sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin, sklearn.base.BaseEstimator)\n",
      " |  LinearSVC(penalty='l2', loss='squared_hinge', *, dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)\n",
      " |  \n",
      " |  Linear Support Vector Classification.\n",
      " |  \n",
      " |  Similar to SVC with parameter kernel='linear', but implemented in terms of\n",
      " |  liblinear rather than libsvm, so it has more flexibility in the choice of\n",
      " |  penalties and loss functions and should scale better to large numbers of\n",
      " |  samples.\n",
      " |  \n",
      " |  This class supports both dense and sparse input and the multiclass support\n",
      " |  is handled according to a one-vs-the-rest scheme.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : {'l1', 'l2'}, default='l2'\n",
      " |      Specifies the norm used in the penalization. The 'l2'\n",
      " |      penalty is the standard used in SVC. The 'l1' leads to ``coef_``\n",
      " |      vectors that are sparse.\n",
      " |  \n",
      " |  loss : {'hinge', 'squared_hinge'}, default='squared_hinge'\n",
      " |      Specifies the loss function. 'hinge' is the standard SVM loss\n",
      " |      (used e.g. by the SVC class) while 'squared_hinge' is the\n",
      " |      square of the hinge loss. The combination of ``penalty='l1'``\n",
      " |      and ``loss='hinge'`` is not supported.\n",
      " |  \n",
      " |  dual : bool, default=True\n",
      " |      Select the algorithm to either solve the dual or primal\n",
      " |      optimization problem. Prefer dual=False when n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive.\n",
      " |  \n",
      " |  multi_class : {'ovr', 'crammer_singer'}, default='ovr'\n",
      " |      Determines the multi-class strategy if `y` contains more than\n",
      " |      two classes.\n",
      " |      ``\"ovr\"`` trains n_classes one-vs-rest classifiers, while\n",
      " |      ``\"crammer_singer\"`` optimizes a joint objective over all classes.\n",
      " |      While `crammer_singer` is interesting from a theoretical perspective\n",
      " |      as it is consistent, it is seldom used in practice as it rarely leads\n",
      " |      to better accuracy and is more expensive to compute.\n",
      " |      If ``\"crammer_singer\"`` is chosen, the options loss, penalty and dual\n",
      " |      will be ignored.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether to calculate the intercept for this model. If set\n",
      " |      to false, no intercept will be used in calculations\n",
      " |      (i.e. data is expected to be already centered).\n",
      " |  \n",
      " |  intercept_scaling : float, default=1\n",
      " |      When self.fit_intercept is True, instance vector x becomes\n",
      " |      ``[x, self.intercept_scaling]``,\n",
      " |      i.e. a \"synthetic\" feature with constant value equals to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes intercept_scaling * synthetic feature weight\n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Set the parameter C of class i to ``class_weight[i]*C`` for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in liblinear that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the pseudo random number generation for shuffling the data for\n",
      " |      the dual coordinate descent (if ``dual=True``). When ``dual=False`` the\n",
      " |      underlying implementation of :class:`LinearSVC` is not random and\n",
      " |      ``random_state`` has no effect on the results.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  max_iter : int, default=1000\n",
      " |      The maximum number of iterations to be run.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : ndarray of shape (1, n_features) if n_classes == 2             else (n_classes, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem).\n",
      " |  \n",
      " |      ``coef_`` is a readonly property derived from ``raw_coef_`` that\n",
      " |      follows the internal memory layout of liblinear.\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (1,) if n_classes == 2 else (n_classes,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The unique classes labels.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Maximum number of iterations run across all classes.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SVC : Implementation of Support Vector Machine classifier using libsvm:\n",
      " |      the kernel can be non-linear but its SMO algorithm does not\n",
      " |      scale to large number of samples as LinearSVC does.\n",
      " |  \n",
      " |      Furthermore SVC multi-class mode is implemented using one\n",
      " |      vs one scheme while LinearSVC uses one vs the rest. It is\n",
      " |      possible to implement one vs the rest with SVC by using the\n",
      " |      :class:`~sklearn.multiclass.OneVsRestClassifier` wrapper.\n",
      " |  \n",
      " |      Finally SVC can fit dense data without memory copy if the input\n",
      " |      is C-contiguous. Sparse data will still incur memory copy though.\n",
      " |  \n",
      " |  sklearn.linear_model.SGDClassifier : SGDClassifier can optimize the same\n",
      " |      cost function as LinearSVC\n",
      " |      by adjusting the penalty and loss parameters. In addition it requires\n",
      " |      less memory, allows incremental (online) learning, and implements\n",
      " |      various loss functions and regularization regimes.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller ``tol`` parameter.\n",
      " |  \n",
      " |  The underlying implementation, liblinear, uses a sparse internal\n",
      " |  representation for the data that will incur a memory copy.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  `LIBLINEAR: A Library for Large Linear Classification\n",
      " |  <https://www.csie.ntu.edu.tw/~cjlin/liblinear/>`__\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.svm import LinearSVC\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_features=4, random_state=0)\n",
      " |  >>> clf = make_pipeline(StandardScaler(),\n",
      " |  ...                     LinearSVC(random_state=0, tol=1e-5))\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('linearsvc', LinearSVC(random_state=0, tol=1e-05))])\n",
      " |  \n",
      " |  >>> print(clf.named_steps['linearsvc'].coef_)\n",
      " |  [[0.141...   0.526... 0.679... 0.493...]]\n",
      " |  \n",
      " |  >>> print(clf.named_steps['linearsvc'].intercept_)\n",
      " |  [0.1693...]\n",
      " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearSVC\n",
      " |      sklearn.linear_model._base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model._base.SparseCoefMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', loss='squared_hinge', *, dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples in the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Array of weights that are assigned to individual\n",
      " |          samples. If not provided,\n",
      " |          then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.18\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          An instance of the estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is proportional to the signed\n",
      " |      distance of that sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "help(LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b070c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import LinearSVC\n",
    "feature_selection = SelectPercentile(f_classif, percentile=10)\n",
    "anova_svc = Pipeline([('anova', feature_selection), ('svc', LinearSVC(max_iter=10000000))])\n",
    "# We can use our ``anova_svc`` object exactly as we were using our ``svc``\n",
    "# object previously.\n",
    "# As we want to investigate our model, we use sklearn `cross_validate` function\n",
    "# with `return_estimator = True` instead of cross_val_score, to save the estimator\n",
    "\n",
    "cv = LeaveOneGroupOut()\n",
    "fitted_pipeline = cross_validate(anova_svc, signals, conditions,\n",
    "                                 cv=cv, groups=groups, return_estimator=True)\n",
    "print(\n",
    "    \"ANOVA+SVC test score: {:.3f}\".format(fitted_pipeline[\"test_score\"].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66059c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     signals, groups, # x & y\n",
    "#     test_size = test_size, \n",
    "#     shuffle = True,\n",
    "#     stratify = groups)\n",
    "# svc.fit(X_train, y_train)\n",
    "\n",
    "# svc.fit(signals, groups)\n",
    "# Here `cv=5` stipulates a 5-fold cross-validation\n",
    "cv_scores = cross_val_score(svc, signals,#sub00.maps_mean_signals,\n",
    "                            groups,#sub00.vectors.condition_labels,\n",
    "                            groups=conditions,\n",
    "                            cv=5)\n",
    "\n",
    "print(\"SVC accuracy: {:.3f}\".format(cv_scores.mean()))\n",
    "\n",
    "cv = LeaveOneGroupOut()\n",
    "cv_scores = cross_val_score(svc, signals,\n",
    "                            groups,\n",
    "                            cv=cv,\n",
    "                            scoring='roc_auc',\n",
    "                            groups=conditions,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "print(\"SVC accuracy (tuned parameters): {:.3f}\".format(cv_scores.mean()))\n",
    "\n",
    "# from sklearn.dummy import DummyClassifier\n",
    "# null_cv_scores = cross_val_score(DummyClassifier(),\n",
    "#                                  sub00.maps_mean_signals,\n",
    "#                                  conditions,\n",
    "#                                  cv=cv,\n",
    "#                                  groups=groups)\n",
    "\n",
    "# print(\"Dummy accuracy: {:.3f}\".format(null_cv_scores.mean()))\n",
    "\n",
    "# from sklearn.model_selection import permutation_test_score\n",
    "# null_cv_scores = permutation_test_score(svc,\n",
    "#                                         sub00.maps_mean_signals,\n",
    "#                                         conditions,\n",
    "#                                         cv=cv,\n",
    "#                                         groups=groups)\n",
    "\n",
    "# print(\"Permutation test score: {:.3f}\".format(null_cv_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d698e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from dltk.io.augmentation import *\n",
    "from dltk.io.preprocessing import *\n",
    "\n",
    "fmriprep_dir = '/data/simexp/cimaq_preproc/fmriprep/'\n",
    "events_dir = '/data/simexp/fnadeau/CIMAQ_AS_BIDS_4/'\n",
    "%matplotlib inline\n",
    "\n",
    "# Timer helper class for benchmarking reading methods\n",
    "class Timer(object):\n",
    "    \"\"\"\n",
    "    Timer class\n",
    "    Wrap a will with a timing function\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.t = time.time()\n",
    "        \n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        print(\"{} took {} seconds\".format(\n",
    "        self.name, time.time() - self.t))\n",
    "# Set up parameters\n",
    "batch_size = 1\n",
    "iterations = sub00.testmean.shape[-1]\n",
    "\n",
    "# Define the desired shapes and types of the training examples to pass to `read_fn`:\n",
    "reader_params = {'n_examples': 1,\n",
    "                 'example_size': list(sub00.testmean.shape),#[128, 224, 224],\n",
    "                 'extract_examples': False}\n",
    "\n",
    "reader_example_shapes = {'features': {'x': reader_params['example_size'] + [1,]},\n",
    "                         'labels': {'y': []}}\n",
    " \n",
    "reader_example_dtypes = {'features': {'x': tf.float32},\n",
    "                         'labels': {'y': tf.int32}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5258fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "def load_data(file_references, y, mode, params=None):\n",
    "    \n",
    "    data = {'features': [], 'labels': []}\n",
    "    sitk_t1 = sitk.ReadImage(file_references)\n",
    "    t1 = whitening(sitk.GetArrayFromImage(sitk_t1))\n",
    "    data['features'].append(images)\n",
    "    data['labels'].append(y.astype(np.int32))\n",
    "\n",
    "    data['features'] = np.array(data['features'])\n",
    "    data['labels'] = np.vstack(data['labels'])\n",
    "    \n",
    "    x = tf.placeholder(reader_example_dtypes['features']['x'], \n",
    "                       [*data['features'], 1])\n",
    "    y = tf.placeholder(reader_example_dtypes['labels']['y'], \n",
    "                       [None, 1])            \n",
    "    return x, y\n",
    "\n",
    "# Load all data into memory\n",
    "data = load_data(sub00.testmean, sub00.vectors.condition_labels,\n",
    "                 tf.estimator.ModeKeys.TRAIN, params=reader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# x = tf.placeholder(reader_example_dtypes['features']['x'], \n",
    "#                    [*data['features'], 1])\n",
    "# y = tf.placeholder(reader_example_dtypes['labels']['y'], \n",
    "#                    [None, 1])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "dataset = dataset.repeat(None)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.prefetch(1)\n",
    "\n",
    "# Check that features and labels dimensions match\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "nx = iterator.get_next()\n",
    "\n",
    "with tf.train.MonitoredTrainingSession() as sess_dict:\n",
    "    # Initialize iterator\n",
    "    sess_dict.run(iterator.initializer,\n",
    "                  feed_dict={x: data['features'],\n",
    "                             y: data['labels']})\n",
    "    \n",
    "    with Timer('Feed dictionary'):\n",
    "        # Timed feed dictionary example\n",
    "        for i in range(iterations):\n",
    "            # Get next features-labels pair\n",
    "            dict_batch_feat, dict_batch_lbl = sess_dict.run(nx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Method 1\n",
    "# def load_data(file_references, mode, params=None):\n",
    "    \n",
    "#     data = {'features': [], 'labels': []}\n",
    "#     sitk_t1 = sitk.ReadImage(file_references)\n",
    "#     t1 = whitening(sitk.GetArrayFromImage(sitk_t1))\n",
    "#     data['features'].append(images)\n",
    "#     data['labels'].append(y.astype(np.int32))\n",
    "\n",
    "#     data['features'] = np.array(data['features'])\n",
    "#     data['labels'] = np.vstack(data['labels'])\n",
    "            \n",
    "#     return data\n",
    "    \n",
    "    # We define a `read_fn` and iterate through the `file_references`, which\n",
    "    # can contain information about the data to be read (e.g. a file path):\n",
    "#     for meta_data in file_references:\n",
    "        \n",
    "        # Here, we parse the `sub_id` to construct a file path to read\n",
    "        # an image from.\n",
    "#         sub_id = meta_data[0]\n",
    "#         data_path = '../../data/IXI_HH/1mm'\n",
    "#         t1_fn = os.path.join(data_path, '{}/T1_1mm.nii.gz'.format(sub_id))\n",
    "        \n",
    "        # Read the .nii image containing a brain volume with SimpleITK and get \n",
    "        # the numpy array:\n",
    "      \n",
    "\n",
    "        # Normalise the image to zero mean/unit std dev:\n",
    "#         t1 = whitening(t1)\n",
    "        \n",
    "        # Create a 4D Tensor with a dummy dimension for channels\n",
    "#         t1 = t1[..., np.newaxis]\n",
    "\n",
    "        # Labels: Here, we parse the class *sex* from the file_references \n",
    "        # \\in [1,2] and shift them to \\in [0,1] for training:\n",
    "#         sex = np.int32(meta_data[1]) - 1\n",
    "#         y = sex\n",
    "#         y = np.int32(sub00.events.trial_type.values)\n",
    "        \n",
    "#         # If training should be done on image patches for improved mixing, \n",
    "#         # memory limitations or class balancing, call a patch extractor\n",
    "#         if params['extract_examples']:\n",
    "#             images = extract_random_example_array(\n",
    "#                 t1,\n",
    "#                 example_size=params['example_size'],\n",
    "#                 n_examples=params['n_examples'])\n",
    "            \n",
    "#             # Loop the extracted image patches\n",
    "#             for e in range(params['n_examples']):\n",
    "#                 data['features'].append(images[e].astype(np.float32))\n",
    "#                 data['labels'].append(y.astype(np.int32))\n",
    "                     \n",
    "#         # If desired (i.e. for evaluation, etc.), return the full images\n",
    "#         else:\n",
    "#             data['features'].append(images)\n",
    "#             data['labels'].append(y.astype(np.int32))\n",
    "\n",
    "#     data['features'] = np.array(data['features'])\n",
    "#     data['labels'] = np.vstack(data['labels'])\n",
    "            \n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac2597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensortest=load_data(sub00.cleaned_fmri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "######## Method 1 continued\n",
    "# Visualise the `dict_batch_feat` using matplotlib.\n",
    "input_tensor_shape = dict_batch_feat.shape\n",
    "center_slices = [s//2 for s in input_tensor_shape]\n",
    "\n",
    "# Visualise the `gen_batch_feat` using matplotlib.\n",
    "f, axarr = plt.subplots(1, input_tensor_shape[0], figsize=(15,5));\n",
    "f.suptitle(' '.join(['Visualisation of the `dict_batch_feat`',\n",
    "                     f'input tensor with shape={input_tensor_shape}']))\n",
    "\n",
    "for batch_id in range(input_tensor_shape[0]):\n",
    "    # Extract a center slice image\n",
    "    img_slice_ = np.squeeze(dict_batch_feat[batch_id, center_slices[1], :, :, :])\n",
    "    img_slice_ = np.flip(img_slice_, axis=0)\n",
    "    \n",
    "    # Plot\n",
    "    axarr[batch_id].imshow(img_slice_, cmap='gray');\n",
    "    axarr[batch_id].axis('off')\n",
    "    axarr[batch_id].set_title('batch_id={}'.format(batch_id))\n",
    "    \n",
    "f.subplots_adjust(wspace=0.05, hspace=0, top=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46fa00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fn(file_references, mode, params=None):\n",
    "    \n",
    "    # We define a `read_fn` and iterate through the `file_references`, which\n",
    "    # can contain information about the data to be read (e.g. a file path):\n",
    "    for meta_data in file_references:\n",
    "        \n",
    "        # Here, we parse the `subject_id` to construct a file path to read\n",
    "        # an image from.\n",
    "        subject_id = meta_data[0]\n",
    "        data_path = '../../data/IXI_HH/1mm'\n",
    "        t1_fn = os.path.join(data_path, '{}/T1_1mm.nii.gz'.format(subject_id))\n",
    "        \n",
    "        # Read the .nii image containing a brain volume with SimpleITK and get \n",
    "        # the numpy array:\n",
    "        sitk_t1 = sitk.ReadImage(t1_fn)\n",
    "        t1 = sitk.GetArrayFromImage(sitk_t1)\n",
    "\n",
    "        # Normalise the image to zero mean/unit std dev:\n",
    "        t1 = whitening(t1)\n",
    "        \n",
    "        # Create a 4D Tensor with a dummy dimension for channels\n",
    "        t1 = t1[..., np.newaxis]\n",
    "        \n",
    "        # If in PREDICT mode, yield the image (because there will be no label\n",
    "        # present). Additionally, yield the sitk.Image pointer (including all\n",
    "        # the header information) and some metadata (e.g. the subject id),\n",
    "        # to facilitate post-processing (e.g. reslicing) and saving.\n",
    "        # This can be useful when you want to use the same read function as \n",
    "        # python generator for deployment.\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            yield {'features': {'x': t1}}\n",
    "\n",
    "        # Labels: Here, we parse the class *sex* from the file_references \n",
    "        # \\in [1,2] and shift them to \\in [0,1] for training:\n",
    "        sex = np.int32(meta_data[1]) - 1\n",
    "        y = sex\n",
    "        \n",
    "        # If training should be done on image patches for improved mixing, \n",
    "        # memory limitations or class balancing, call a patch extractor\n",
    "        if params['extract_examples']:\n",
    "            images = extract_random_example_array(\n",
    "                t1,\n",
    "                example_size=params['example_size'],\n",
    "                n_examples=params['n_examples'])\n",
    "            \n",
    "            # Loop the extracted image patches and yield\n",
    "            for e in range(params['n_examples']):\n",
    "                yield {'features': {'x': images[e].astype(np.float32)},\n",
    "                       'labels': {'y': y.astype(np.int32)}}\n",
    "                     \n",
    "        # If desired (i.e. for evaluation, etc.), return the full images\n",
    "        else:\n",
    "            yield {'features': {'x': images},\n",
    "                   'labels': {'y': y.astype(np.int32)}}\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1005709",
   "metadata": {},
   "outputs": [],
   "source": [
    "path00='/data/simexp/fnadeau/cimaq_2d/sub-3002498/ses-V10/func/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'\n",
    "# path00 = Path(path00)\n",
    "# # dir(path00)\n",
    "# # path00.split(path00.suffixes[0])[0]\n",
    "# justname = str(path00).rstrip(''.join(path00.suffixes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa52d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fmriprep_mask(fmri_path:Union[str,os.PathLike],\n",
    "                      mask_ext:str='nii.gz', **kwargs):\n",
    "    bids_patt = lambda p: f'(?<={p})[a-zA-Z0-9]*'\n",
    "    prefixes = ['sub-','ses-','task-','space-']\n",
    "    mask_sfx = '_'.join([pf+re.search(bids_patt(pf),\n",
    "                                      os.path.basename(fmri_path)).group()\n",
    "                         for pf in prefixes]+[f'desc-brain_mask.{mask_ext}'])\n",
    "    return glob.glob(os.path.join(os.path.dirname(fmri_path), mask_sfx))[0]\n",
    "\n",
    "def get_fmriprep_anat(fmri_path:Union[str,os.PathLike],\n",
    "                      mdlt:str='T1w', ext:str='nii.gz',\n",
    "                      **kwargs):\n",
    "    space = '_space-'+re.search(f'(?<=_space-)[a-zA-Z0-9]*',\n",
    "                      os.path.basename(fmri_path)).group()\n",
    "    anat_suffix = f'*{space}_desc-preproc_{mdlt}.{ext}'\n",
    "    return str(next(list(Path(fmri_path).parents)[2].rglob(anat_suffix)))\n",
    "\n",
    "def get_events(fmri_path:Union[str,os.PathLike],\n",
    "               events_dir:Union[str,os.PathLike])->str:\n",
    "    sub_id, ses_id = Path(fmri_path).parts[-4:-2]\n",
    "    globbed = glob.glob(os.path.join(events_dir,\n",
    "                                  *Path(fmri_path).parts[-4:-2],\n",
    "                                  '*events.tsv'))\n",
    "    return [False if globbed == [] else globbed[0]][0]\n",
    "\n",
    "        \n",
    "def fetch_fmriprep_session(fmri_path:Union[str,os.PathLike],\n",
    "                           events_dir:Union[str,os.PathLike],\n",
    "                           strategy:str='Minimal',\n",
    "                           anat_mod:str='T1w',\n",
    "                           lc_kws:dict=None,\n",
    "                           clean_kws:dict=None,\n",
    "                           **kwargs):\n",
    "    import load_confounds\n",
    "    from inspect import getmembers\n",
    "    from sklearn.utils import Bunch\n",
    "    from pathlib import Path\n",
    "    sub_id, ses_id = Path(fmri_path).parts[-4:-2]\n",
    "    mask_path = get_fmriprep_mask(fmri_path)\n",
    "    anat_path = get_fmriprep_anat(fmri_path)\n",
    "    loader = dict(getmembers(load_confounds))[f'{strategy}']\n",
    "    loader = [loader(**lc_kws) if lc_kws is not None\n",
    "              else loader()][0]    \n",
    "    event_path = get_events(fmri_path,events_dir)\n",
    "    if event_path is False:\n",
    "        return False\n",
    "    else:\n",
    "        return Bunch(**dict(sub_id=sub_id, ses_id=ses_id,\n",
    "                            full_mask_path=mask_path,\n",
    "                            fmri_path=fmri_path,\n",
    "                            anat_path=anat_path,\n",
    "                            event_path=event_path,\n",
    "                            loader=loader,\n",
    "                            confounds_strategy=strategy))\n",
    "\n",
    "def load_fmriprep_session(fmri_path:Union[str,os.PathLike],\n",
    "                          events_dir:Union[str,os.PathLike],\n",
    "                          clean_kws:dict=None,\n",
    "                          masker_kws:dict=None,\n",
    "                          **kwargs):\n",
    "    from nilearn import image as nimage\n",
    "    from nilearn.masking import apply_mask, unmask\n",
    "    from nilearn.signal import clean\n",
    "    from sklearn.utils import Bunch\n",
    "    from glob import glob\n",
    "    from nilearn import image as nimage\n",
    "    session = fetch_fmriprep_session(fmri_path,events_dir)\n",
    "    fmri_img, mask_img, anat_img = \\\n",
    "        tuple(map(nimage.load_img,[session.fmri_path, session.full_mask_path,\n",
    "                                   session.anat_path]))\n",
    "    t_r = fmri_img.header.get_zooms()[-1]\n",
    "    conf = session.loader.load(session.fmri_path)\n",
    "    clean_defs = dict(standardize=False,\n",
    "                      standardize_confounds=False,\n",
    "                      high_pass=None, low_pass=None,\n",
    "                      t_r=fmri_img.header.get_zooms()[-1],\n",
    "                      ensure_finite=True)\n",
    "    masker_defs = dict(mask_img=mask_img,\n",
    "                       allow_overlap=True, t_r=t_r,\n",
    "                       standardize_confounds=False,\n",
    "                       resampling_target='mask')\n",
    "    if masker_kws is not None:\n",
    "        masker_defs.update(masker_kws)\n",
    "    if clean_kws is not None:\n",
    "        clean_defs.update(clean_kws)\n",
    "    cleaned_fmri = unmask(clean(apply_mask(fmri_img, mask_img,\n",
    "                                           smoothing_fwhm=8,\n",
    "                                           dtype='f'),\n",
    "                                confounds=conf,\n",
    "                                **clean_defs),\n",
    "                          mask_img)\n",
    "    cleaned_fmri = nimage.new_img_like(fmri_img, cleaned_fmri.get_fdata(),\n",
    "                               copy_header=True)\n",
    "    events = pd.read_csv(session.event_path, sep='\\t').iloc[1:,:]\n",
    "    loaded = Bunch(**dict(fmri_img=fmri_img, cleaned_fmri=cleaned_fmri,\n",
    "                          full_mask_img=mask_img, anat_img=anat_img,\n",
    "                          clean_params=clean_defs, masker_params=masker_defs,\n",
    "                          confounds=conf, events=events, t_r=t_r))\n",
    "    loaded.update(session)\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def rot90flip(data, rot_angle:int=None, scl, vol):\n",
    "    \n",
    "rot90flip=lambda a, s, v: np.rot90(a[:,:,s,v])\n",
    "rot180flip=lambda a, s, v: np.rot90(np.rot90(a[:,:,s,v]))\n",
    "rot270flip=lambda a, s, v: np.rot90(np.rot90(np.rot90(a[:,:,s,v])))\n",
    "rot_dict = {90: rot90flip, 180: rot180flip, 270: rot270flip}\n",
    "rot_dict[90]([0,1,2], 2, 3)\n",
    "# np.rot90([[0,1,2]][:, :, 2, 33])\n",
    "# import scipy\n",
    "# dir(scipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a88560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980a9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = '../../flat_bold_png/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold_t306_z46.png'\n",
    "\n",
    "\n",
    "# imageio.imread(src).shape\n",
    "help(np.repeat)\n",
    "\n",
    "# Image.open(src)._Image__transformer()\n",
    "# dir(img._Image__transformer)\n",
    "# skimage.show(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e182c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "cimaq_stims = list(map(str, list(Path('../../WMStim').rglob('*.bmp'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b794fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(src:Union[str,os.PathLike]):\n",
    "    # Open image\n",
    "#     input_image = PIL.Image.fromarray(np.uint8(PIL.Image.open(src)))\n",
    "#     input_image = PIL.Image.fromarray(PIL.Image.open(src))\n",
    "    input_image = PIL.Image.open(src)\n",
    "    # Preprocess image\n",
    "    preprocess = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                          std=[0.229, 0.224, 0.225])])\n",
    "    return preprocess(input_image).unsqueeze(0)\n",
    "preprocess_image(cimaq_stims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(imageio.imread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c576dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(filter(lambda x: x.endswith('.bmp'), cimaq_stims)))==len(cimaq_stims)\n",
    "sorted(cimaq_stims)[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a287f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GoogLeNet.from_pretrained(\"googlenet\")\n",
    "\n",
    "def get_features(src, model):\n",
    "#     input_tensor = preprocess_image(src)\n",
    "#     model.eval()\n",
    "    return model.extract_features(preprocess_image(src))\n",
    "features = [get_features(src, model) for src in sorted(cimaq_stims)[6:]]\n",
    "labels = list(map(os.path.basename, sorted(cimaq_stims)[6:]))\n",
    "# list(get_features(cimaq_stims[x], model) for x in range(len(cimaq_stims)))\n",
    "# help(model.eval)\n",
    "# eval mode shape == torch.Size([1, 1024, 7, 7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc902a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "apath = '../../flat_bold_png/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold_t306_z46.png'\n",
    "from googlenet_pytorch import GoogLeNet\n",
    "from typing import Union\n",
    "# model = GoogLeNet.from_pretrained(\"ImageNet\")\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import skimage\n",
    "import imageio\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from googlenet_pytorch import GoogLeNet \n",
    "\n",
    "\n",
    "def load_inputs(src:Union[str,os.PathLike]):\n",
    "    # Open image\n",
    "#     input_image = PIL.Image.open(BytesIO(imageio.imread(src)))\n",
    "#     model = VGG16()\n",
    "    model = GoogLeNet.from_pretrained(\"googlenet\")\n",
    "    input_image = PIL.Image.fromarray(np.stack(np.repeat(np.uint8(PIL.Image.open(src)),3, axis=0)))\n",
    "    # Preprocess image\n",
    "    preprocess = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                          std=[0.229, 0.224, 0.225])])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # create a mini-batch as expected by the model\n",
    "\n",
    "    # Load class names\n",
    "#     labels_map = json.load(open(\"labels_map.txt\"))\n",
    "#     labels_map = [labels_map[str(i)] for i in range(1000)]\n",
    "\n",
    "    # Feature extraction\n",
    "    # ... image preprocessing as in the classification example ...\n",
    "    # inputs = torch.randn(1, 3, 224, 224)\n",
    "#     print(inputs.shape) # torch.Size([1, 3, 224, 224])\n",
    "\n",
    "    features = model.extract_features(input_batch)\n",
    "    print(features.shape) # torch.Size([1, 1024, 7, 7])\n",
    "\n",
    "    # Classify with GoogLeNet\n",
    "    model.eval()\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to(\"cuda\")\n",
    "        model.to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_batch)\n",
    "        preds = torch.topk(logits, k=5).indices.squeeze(0).tolist()\n",
    "        print(\"-----\")\n",
    "        print(f'Predictions: {preds}')\n",
    "        for idx in preds:\n",
    "#             label = labels_map[idx]\n",
    "            prob = torch.softmax(logits, dim=1)[0, idx].item()\n",
    "#             print(f\"{label:<75} ({prob * 100:.2f}%)\")\n",
    "    return input_tensor, input_batch, features, prob\n",
    "test_tensors, test_batch, test_features, test_prob = load_inputs(cimaq_stims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b8d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec8c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from googlenet_pytorch import GoogLeNet\n",
    "from numpy import asarray\n",
    "model = GoogLeNet.from_pretrained('ImageNet')\n",
    "apath = '../../flat_bold_png/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold/sub-3002498_ses-V10_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold_t306_z46.png'\n",
    "from typing import Union\n",
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from googlenet_pytorch import GoogLeNet \n",
    "# ... image preprocessing as in the classification example ...\n",
    "# inputs = torch.randn(1, 3, 224, 224)\n",
    "# inputs = sorted(map(str,list(Path(testsess).iterdir())))\n",
    "# input_image = asarray(Image.open(apath))\n",
    "preprocess = transforms.Compose([transforms.Resize(256),\n",
    "                                 transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                      std=[0.229, 0.224, 0.225])])\n",
    "input_tensor = preprocess(Image.open(apath))\n",
    "print(input_tensor.shape) # torch.Size([1, 3, 224, 224])\n",
    "\n",
    "features = model.extract_features(input_tensor)\n",
    "torch.Size([1, 1024, 7, 7])\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d46edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(Image.open(apath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7facb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c631cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlenet_pytorch import GoogLeNet\n",
    "model = GoogLeNet.from_pretrained(\"googlenet\")\n",
    "\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from googlenet_pytorch import GoogLeNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6111664",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U IProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7966b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56801597",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('sub-3163875_ses-V03_task-memory_space-MNI152NLin2009cAsym_desc-preproc_bold'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29772374",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatdir = '../../flat_bold_png/'\n",
    "from itertools import starmap\n",
    "from pathlib import Path\n",
    "testsess = sorted(Path(flatdir).iterdir())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ca3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca36129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(list(Path(testsess).iterdir())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684637a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
