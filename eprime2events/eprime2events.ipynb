{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "from numpy import nan as NaN\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "\n",
    "def get_arguments():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "        description=\"\",\n",
    "        epilog=\"\"\"\n",
    "        Convert behavioural data from cimaq to bids format\n",
    "        Input: Folder with zip files\n",
    "        \"\"\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"-d\", \"--idir\",\n",
    "        required=True, nargs=\"+\",\n",
    "        help=\"Folder to be sorted\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"-o\", \"--odir\",\n",
    "        required=True, nargs=\"+\",\n",
    "        help=\"Output folder - if doesn\\'t exist it will be created.\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--log_level', default='INFO',\n",
    "        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],\n",
    "        help='Log level of the logging class.')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    if len(sys.argv) == 1:\n",
    "        parser.print_help()\n",
    "        sys.exit()\n",
    "    else:\n",
    "        return args\n",
    "\n",
    "\n",
    "def get_all_ids(iFolder):\n",
    "    \"\"\" List all ZipFile and get all IDs\n",
    "    Parameters:\n",
    "    ----------\n",
    "    iFolder: string (input folder)\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    ids: list of tuple (behavioral ID, IRM ID)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(iFolder):\n",
    "        sys.exit('This folder doesn\\'t exist: {}'.format(iFolder))\n",
    "        return\n",
    "    ids = []\n",
    "    allZipFiles = glob.glob(os.path.join(iFolder, '*.zip'))\n",
    "    for currZipFile in allZipFiles:\n",
    "        currZipFile = os.path.basename(currZipFile)\n",
    "        ids.append((currZipFile.split('_')[0], currZipFile.split('_')[1]))\n",
    "\n",
    "    if not ids:\n",
    "        sys.exit('This folder doesn\\'t contain any zip files')\n",
    "        return\n",
    "    else:\n",
    "        return ids\n",
    "\n",
    "\n",
    "def set_subject_data(bID, iFolder, oFolder):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    bID: string (PSCID used to identify participants during data collection)\n",
    "    datadir: string (input folder)\n",
    "    oFolder: string (output folder)\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    sub_files: list (three input files)\n",
    "    \"\"\"\n",
    "    logging.debug('Subject PSCID\": {}'.format(bID))\n",
    "\n",
    "    prefix = ['Output-Responses-Encoding_CIMAQ_*',\n",
    "              'Onset-Event-Encoding_CIMAQ_*',\n",
    "              'Output_Retrieval_CIMAQ_*']\n",
    "\n",
    "    sub_files = []\n",
    "    s_dir = glob.glob(os.path.join(iFolder, bID+'*IRM.zip'))\n",
    "\n",
    "    if len(s_dir) != 1:\n",
    "        logging.error(' Multiple directories match \\\n",
    "                       this subject PSCID: {}'.format(bID))\n",
    "    else:\n",
    "        s_path = os.path.join(oFolder, bID+'*')\n",
    "        s_out = glob.glob(s_path)\n",
    "        if not s_out:\n",
    "            z_ref = zipfile.ZipFile(s_dir[0], 'r')\n",
    "            z_ref.extractall(oFolder)\n",
    "            z_ref.close()\n",
    "            s_out = glob.glob(s_path)\n",
    "\n",
    "        if len(s_out) == 1:\n",
    "            s_out = s_out[0]\n",
    "            for nPrefix in prefix:\n",
    "                file = glob.glob(os.path.join(s_out, nPrefix))\n",
    "                if len(file) == 1:\n",
    "                    sub_files.append(file[0])\n",
    "                else:\n",
    "                    logging.error('Multiple files found'.format(bID))\n",
    "        else:\n",
    "            logging.error('Multiple folders found'.format(bID))\n",
    "\n",
    "    return sub_files\n",
    "\n",
    "\n",
    "def cleanMain(mainFile):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    mainFile: pandas object\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    mainFile: pandas object\n",
    "    \"\"\"\n",
    "    # remove first three junk rows (blank trials): CTL0, Enc00 and ENc000\n",
    "    mainFile.drop([0, 1, 2], axis=0, inplace=True)\n",
    "    # re-label columns\n",
    "    mainFile.rename(columns={'TrialNumber': 'trial_number',\n",
    "                             'Category': 'trial_type',\n",
    "                             'OldNumber': 'stim_id',\n",
    "                             'CorrectSource': 'position_correct',\n",
    "                             'Stim_RESP': 'response',\n",
    "                             'Stim_RT': 'response_time'}, inplace=True)\n",
    "    # remove redundant columns\n",
    "    mainFile.drop(['TrialCode', 'Stim_ACC'], axis=1, inplace=True)\n",
    "    # re-order columns\n",
    "    cols = ['trial_number', 'trial_type', 'response', 'response_time',\n",
    "            'stim_id', 'position_correct']\n",
    "    mainFile = mainFile[cols]\n",
    "    # change in-scan reaction time from ms to s\n",
    "    mainFile['response_time'] = mainFile['response_time'].astype('float64',\n",
    "                                                                 copy=False)\n",
    "    mainFile['response_time'] = mainFile['response_time'].div(1000)\n",
    "    # insert new columns\n",
    "    colNames = ['onset', 'duration', 'offset', 'stim_file', 'stim_category',\n",
    "                'stim_name', 'recognition_accuracy',\n",
    "                'recognition_responsetime', 'position_response',\n",
    "                'position_accuracy', 'position_responsetime']\n",
    "    dtype = [NaN, NaN, NaN, 'None', 'None', 'None', -1, NaN, -1, -1, NaN]\n",
    "    colIndex = [0, 1, 2, 8, 9, 10, 11, 12, 14, 15, 16]\n",
    "    for i in range(0, 11):\n",
    "        mainFile.insert(loc=colIndex[i],\n",
    "                        column=colNames[i],\n",
    "                        value=dtype[i],\n",
    "                        allow_duplicates=True)\n",
    "    return mainFile  # modified in-place\n",
    "\n",
    "\n",
    "def cleanOnsets(onsets):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Label columns and remove first six junk rows\n",
    "        (3 junk trials; 2 rows per trial).\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    onsets: pandas object\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    onsets: pandas object\n",
    "    \"\"\"\n",
    "    # add column headers\n",
    "    onsets.columns = [\"TrialNum\", \"Condition\", \"TrialNum_perCondi\",\n",
    "                      \"ImageID\", \"Trial_part\", \"onsetSec\", \"durationSec\"]\n",
    "    onsets.drop([0, 1, 2, 3, 4, 5], axis=0, inplace=True)\n",
    "    return onsets\n",
    "\n",
    "\n",
    "def cleanRetriev(ret):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    ret: pandas object\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    ret: pandas object\n",
    "    \"\"\"\n",
    "    # Change column headers\n",
    "    ret.rename(columns={'category': 'old_new',\n",
    "                        'Stim': 'stim_file',\n",
    "                        'OldNumber': 'stim_id',\n",
    "                        'Recognition_ACC': 'recognition_accuracy',\n",
    "                        'Recognition_RESP': 'recognition_response',\n",
    "                        'Recognition_RT': 'recognition_responsetime',\n",
    "                        'Spatial_RESP': 'position_response',\n",
    "                        'Spatial_RT': 'position_responsetime',\n",
    "                        'Spatial_ACC(Ã  corriger voir output-encodage)': 'position_accuracy'},\n",
    "               inplace=True)\n",
    "    # re-order columns\n",
    "    cols = ['old_new', 'stim_file', 'stim_id', 'recognition_response',\n",
    "            'recognition_accuracy', 'recognition_responsetime',\n",
    "            'position_response', 'position_accuracy', 'position_responsetime']\n",
    "    ret = ret[cols]\n",
    "    # Transform reaction time columns from ms to s\n",
    "    ret[['recognition_responsetime']] = ret[['recognition_responsetime']].astype('float64', copy=False)  # string is object in pandas, str in Python\n",
    "    ret[['position_responsetime']] = ret[['position_responsetime']].astype('float64', copy=False)\n",
    "    ret['recognition_responsetime'] = ret['recognition_responsetime'].div(1000)\n",
    "    ret['position_responsetime'] = ret['position_responsetime'].div(1000)\n",
    "    # Clean up eprime programming mistake: replace position_response and position_responsetime values\n",
    "    # with NaN if subject perceived image as 'new' (the image was not probed for position).\n",
    "    # There should be no response or RT value there, values were carried over from previous trial (not reset in eprime)\n",
    "    # CONFIRMED w Isabel: subject must give a position answer when probed (image considered OLD) before eprime moves to the next trial.\n",
    "    i = ret[ret['recognition_response'] == 2].index\n",
    "    ret.loc[i, 'position_responsetime'] = NaN\n",
    "    ret.loc[i, 'position_response'] = -1\n",
    "    # clean up eprime mistake (change Old67 condition ('old_new') from New to OLD)\n",
    "    q = ret[ret['stim_id'] == 'Old67'].index\n",
    "    ret.loc[q, 'old_new'] = 'OLD'\n",
    "    # insert new columns\n",
    "    colNames = ['trial_number', 'stim_category', 'stim_name',\n",
    "                'recognition_performance', 'position_correct']\n",
    "    dtype = [-1, 'None', 'None', 'None', -1]\n",
    "    colIndex = [0, 4, 5, 9, 10]\n",
    "    for j in range(0, 5):\n",
    "        ret.insert(loc=colIndex[j], column=colNames[j], value=dtype[j],\n",
    "                   allow_duplicates=True)\n",
    "    # Extract info and fill trial_number, stim_category and stim_name columns\n",
    "    k = ret.index\n",
    "    ret.loc[k, 'trial_number'] = k+1\n",
    "    # format: category_imageName.bmp w some space, _ and - in image names\n",
    "    stimInfo = ret.loc[k, 'stim_file']\n",
    "    for s in k:\n",
    "        ret.loc[s, 'stim_category'] = re.findall('(.+?)_', stimInfo[s])[0]\n",
    "        ret.loc[s, 'stim_name'] = re.findall('_(.+?)[.]', stimInfo[s])[0]\n",
    "    # Fill recognition_performance column based on actual and perceived novelty\n",
    "    m = ret[ret['old_new'] == 'OLD'].index.intersection(ret[ret['recognition_accuracy'] == 1].index)\n",
    "    ret.loc[m, 'recognition_performance'] = 'Hit'\n",
    "    n = ret[ret['old_new'] == 'OLD'].index.intersection(ret[ret['recognition_accuracy'] == 0].index)\n",
    "    ret.loc[n, 'recognition_performance'] = 'Miss'\n",
    "    o = ret[ret['old_new'] == 'New'].index.intersection(ret[ret['recognition_accuracy'] == 1].index)\n",
    "    ret.loc[o, 'recognition_performance'] = 'CR'\n",
    "    p = ret[ret['old_new'] == 'New'].index.intersection(ret[ret['recognition_accuracy'] == 0].index)\n",
    "    ret.loc[p, 'recognition_performance'] = 'FA'\n",
    "    # return cleaned up input Dataframe\n",
    "    return ret\n",
    "\n",
    "\n",
    "def addOnsets(main, enc):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    main:\n",
    "    enc: pandas objects\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    main: pandas object\n",
    "    \"\"\"\n",
    "\n",
    "    # make main file indexable by trial number:\n",
    "    main.set_index('trial_number', inplace=True)\n",
    "    # copy trial onset and offset times from enc into main\n",
    "    # note: fixation's onset time is the trial task's offset time\n",
    "    for i in enc.index:\n",
    "        trialNum = enc.loc[i, 'TrialNum']\n",
    "        if enc.loc[i, 'Trial_part'] == 'Fixation':\n",
    "            main.loc[trialNum, 'offset'] = enc.loc[i, 'onsetSec']\n",
    "        else:\n",
    "            main.loc[trialNum, 'onset'] = enc.loc[i, 'onsetSec']\n",
    "    # Calculate trial duration time from onset and offset times\n",
    "    main['duration'] = main['offset']-main['onset']\n",
    "    # reset main's searchable index to default\n",
    "    main.reset_index(level=None, drop=False, inplace=True)\n",
    "    return main\n",
    "\n",
    "\n",
    "def addPostScan(main, ret):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    main: panda object\n",
    "    ret: panda object\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    mainMerged: pandas object\n",
    "    \"\"\"\n",
    "    # split main's rows (trials) into sublist based on Condition\n",
    "    mainEnc = main[main['trial_type'] == 'Enc'].copy()\n",
    "    mainCTL = main[main['trial_type'] == 'CTL'].copy()\n",
    "    # make mainEnc indexable by picture id\n",
    "    mainEnc.set_index('stim_id', inplace=True)\n",
    "    # import post-scan data from ret into mainEnc\n",
    "    for i in ret[ret['old_new'] == 'OLD'].index:\n",
    "        stimID = ret.loc[i, 'stim_id']\n",
    "        mainEnc.loc[stimID, 'stim_category'] = ret.loc[i, 'stim_category']\n",
    "        mainEnc.loc[stimID, 'stim_name'] = ret.loc[i, 'stim_name']\n",
    "        mainEnc.loc[stimID, 'recognition_accuracy'] = ret.loc[i, 'recognition_accuracy']\n",
    "        mainEnc.loc[stimID, 'recognition_responsetime'] = ret.loc[i, 'recognition_responsetime']\n",
    "        mainEnc.loc[stimID, 'position_response'] = ret.loc[i, 'position_response']\n",
    "        mainEnc.loc[stimID, 'position_responsetime'] = ret.loc[i, 'position_responsetime']\n",
    "    # calculate post-scan source (position) accuracy;\n",
    "    #  -1 = control task; 0 = missed trial; 1 = wrong source (image recognized but wrong quadrant remembered);\n",
    "    # 2 = image recognized with correct source\n",
    "    mainEnc['position_accuracy'] = 0\n",
    "    for j in mainEnc[mainEnc['recognition_accuracy'] == 1].index:\n",
    "        if mainEnc.loc[j, 'position_correct'] == mainEnc.loc[j, 'position_response']:\n",
    "            mainEnc.loc[j, 'position_accuracy'] = 2\n",
    "        else:\n",
    "            mainEnc.loc[j, 'position_accuracy'] = 1\n",
    "    # import source accuracy info from mainEnc into ret (in-place)\n",
    "    for i in ret[ret['old_new'] == 'OLD'].index:\n",
    "        picID = ret.loc[i, 'stim_id']\n",
    "        ret.loc[i, 'position_correct'] = mainEnc.loc[picID, 'position_correct']\n",
    "        ret.loc[i, 'position_accuracy'] = mainEnc.loc[picID,\n",
    "                                                      'position_accuracy']\n",
    "    # reset mainEnc searchable index to default\n",
    "    # and re-order columns to match order in mainCTL\n",
    "    mainEnc.reset_index(level=None, drop=False, inplace=True)\n",
    "    cols = ['trial_number', 'onset', 'duration', 'offset', 'trial_type',\n",
    "            'response', 'response_time', 'stim_id', 'stim_file',\n",
    "            'stim_category', 'stim_name', 'recognition_accuracy',\n",
    "            'recognition_responsetime', 'position_correct',\n",
    "            'position_response', 'position_accuracy', 'position_responsetime']\n",
    "    mainEnc = mainEnc[cols]\n",
    "    # Re-merge mainEnc and mainCTL and re-order by trial number\n",
    "    mainMerged = mainEnc.append(mainCTL, ignore_index=True)\n",
    "    mainMerged.sort_values('trial_number', axis=0, ascending=True,\n",
    "                           inplace=True)\n",
    "    return mainMerged\n",
    "\n",
    "\n",
    "def extract_taskFile(bID, sID, file_list, output):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    bID: string (subject PSCID, id used during data collection)\n",
    "    sID: string (subject DCCID, id used in Loris)\n",
    "    file_list: list (three input files)\n",
    "    output: string (output Folder)\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # import data from three text files into pandas DataFrames\n",
    "    encMain = pd.read_csv(file_list[0], sep='\\t')\n",
    "    manualEdits = ['3303819', '5477234', '6417837', '7674650']\n",
    "    if bID in manualEdits:\n",
    "        encOnsets = pd.read_csv(file_list[1], sep='\\t', header=None)\n",
    "    else:\n",
    "        encOnsets = pd.read_fwf(file_list[1], infer_nrows=210,\n",
    "                                delim_whitespace=True,\n",
    "                                header=None)\n",
    "    retriev = pd.read_csv(file_list[2], sep='\\t', encoding='ISO-8859-1')\n",
    "    # clean up each file\n",
    "    encMain = cleanMain(encMain)\n",
    "    encOnsets = cleanOnsets(encOnsets)\n",
    "    retriev = cleanRetriev(retriev)\n",
    "    # import onset times from encOnset into encMain\n",
    "    encMain = addOnsets(encMain, encOnsets)\n",
    "    # import post-scan performance data from retriev into encMain\n",
    "    encMain = addPostScan(encMain, retriev)\n",
    "    # export encMain and retriev into tsv files (output directorty)\n",
    "    encMain.to_csv(output+'/sub-'+sID+'_ses-4_task-memory_events.tsv',\n",
    "                   sep='\\t', header=True, index=False)\n",
    "    retriev.to_csv(output+'/PostScanBehav_pscid'+bID+'_dccid'+sID+'.tsv',\n",
    "                   sep='\\t', header=True, index=False)\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = get_arguments()\n",
    "    logging.basicConfig(level=args.log_level)\n",
    "    oFolder = args.odir[0]\n",
    "    iFolder = args.idir[0]\n",
    "\n",
    "    # Create oFolder if not exists\n",
    "    if not os.path.exists(oFolder):\n",
    "        os.mkdir(oFolder)\n",
    "\n",
    "    all_ids = get_all_ids(iFolder)\n",
    "    # Create tmp folder to temporaly store unziped files\n",
    "    tmpFolder = os.path.join(oFolder, 'tmp')\n",
    "    if not os.path.exists(tmpFolder):\n",
    "        os.mkdir(tmpFolder)\n",
    "\n",
    "    # Create taskFiles folder where all output files will be saved\n",
    "    fileFolder = os.path.join(oFolder, 'taskfiles')\n",
    "    if not os.path.exists(fileFolder):\n",
    "        os.mkdir(fileFolder)\n",
    "\n",
    "    # loop over zip files\n",
    "    for (idBEH, idMRI) in all_ids:\n",
    "        s_files = set_subject_data(idBEH, iFolder, tmpFolder)\n",
    "        if(len(s_files) == 3):\n",
    "            extract_taskFile(idBEH, idMRI, s_files, fileFolder)\n",
    "            shutil.rmtree(tmpFolder, ignore_errors=True)\n",
    "        else:\n",
    "            logging.info('missing files for subject ({},{})'.format(idBEH,\n",
    "                                                                    idMRI))\n",
    "\n",
    "            #\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sys.exit(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
