{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between-subject SVR (Support Vector Regression) prediction of latent memory score computed with PCA on battery of neuropysch test scores, based on fMRI contrast (CIMAQ memory encoding task) between task conditions in entire brain's voxels.\n",
    "\n",
    "Trials (conditions) are classifierd according to:\n",
    "task condition (encoding or control task)\n",
    "memory performance (hit vs miss, correct vs incorrect source)\n",
    "stimulus category (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nilearn\n",
    "import scipy\n",
    "import nibabel as nb\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from numpy import nan as NaN\n",
    "from matplotlib import pyplot as plt\n",
    "from nilearn import image, plotting\n",
    "from nilearn import masking\n",
    "from nilearn import plotting\n",
    "from nilearn import datasets\n",
    "from nilearn.plotting import plot_stat_map, plot_roi, plot_anat, plot_img, show\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, f1_score\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: import list of participants, and generate sublists of participants who have enough trials per category to have proper contrasts between conditions \n",
    "\n",
    "1. Encoding vs Control tasks contrast (all 94 participants)\n",
    "\n",
    "3. Hit versus Miss contrast (? participants; at least 10 trials per condition)\n",
    "\n",
    "4. Correct Source versus Wrong Source (? participants; at least 10 trials per condition)\n",
    "\n",
    "5. Correct Source versus Miss (? participants; at least 10 trials per condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to directory with participant lists\n",
    "data_file = '/Users/mombot/Documents/Simexp/CIMAQ/Data/Participants/Splitting/Sub_list.tsv'\n",
    "sub_data = pd.read_csv(data_file, sep = '\\t')\n",
    "\n",
    "# Exclude participants who failed QC\n",
    "sub_data = sub_data[sub_data['QC_status']!= 'F']\n",
    "\n",
    "# Set minimal number of trials needed per subject to include them in analysis\n",
    "num = 9\n",
    "\n",
    "# Encoding vs Control, and Stimulus Category classifications\n",
    "all_subs = sub_data['participant_id']\n",
    "all_diagnosis = sub_data['cognitive_status']\n",
    "all_memScore = sub_data['Fac1_memory']\n",
    "print(all_subs)\n",
    "print(len(all_subs))\n",
    "\n",
    "# Hit versus Miss\n",
    "hm_data = sub_data[sub_data['hits'] > num]\n",
    "hm_data = hm_data[hm_data['miss'] > num]\n",
    "hm_subs = hm_data['participant_id']\n",
    "hm_diagnosis = hm_data['cognitive_status']\n",
    "hm_memScore = hm_data['Fac1_memory']\n",
    "print(hm_subs)\n",
    "print(len(hm_subs))\n",
    "\n",
    "# Correct Source versus Wrong Source \n",
    "cw_data = sub_data[sub_data['correct_source'] > num]\n",
    "cw_data = cw_data[cw_data['wrong_source'] > num]\n",
    "cw_subs = cw_data['participant_id']\n",
    "cw_diagnosis = cw_data['cognitive_status']\n",
    "cw_memScore = cw_data['Fac1_memory']\n",
    "print(cw_subs)\n",
    "print(len(cw_subs))\n",
    "\n",
    "# Correct Source versus Miss\n",
    "cmiss_data = sub_data[sub_data['correct_source'] > num]\n",
    "cmiss_data = cmiss_data[cmiss_data['miss'] > num]\n",
    "cmiss_subs = cmiss_data['participant_id']\n",
    "cmiss_diagnosis = cmiss_data['cognitive_status']\n",
    "cmiss_memScore = cmiss_data['Fac1_memory']\n",
    "print(cmiss_subs)\n",
    "print(len(cmiss_subs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: For each subject list (analysis), create a group mask from individual functional mri masks.\n",
    "\n",
    "The mask should only include voxels included in all participants's individual functional mask (intersection). The mask will serve to vectorize 3D beta weigths maps into feature rows.\n",
    "**Update: use 0.5 treshold, otherwise too much signal drop out**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anatomical template for display\n",
    "anat = '/Users/mombot/Documents/Simexp/CIMAQ/Data/Templates/template_anat_stereo.nii'\n",
    "\n",
    "# Path to directory with masks\n",
    "mask_dir = '/Users/mombot/Documents/Simexp/CIMAQ/Data/masks'\n",
    "\n",
    "# All participants (94 participants)\n",
    "all_mask_list = []\n",
    "for sub in all_subs:\n",
    "    mask = os.path.join(mask_dir, 'func_sub'+str(sub)+'_mask_stereonl.nii')\n",
    "    all_mask_list.append(mask)\n",
    "print(len(all_mask_list))    \n",
    "grp_mask_all = masking.intersect_masks(mask_imgs = all_mask_list, threshold=0.5, connected=True)    \n",
    "\n",
    "# plotting.plot_roi(roi_img=grp_mask_all, bg_img=anat, cut_coords=(0, -7, -7), cmap='Paired')\n",
    "#plotting.view_img(grp_mask_all, bg_img=anat, resampling_interpolation='nearest')\n",
    "\n",
    "# Hit versus miss (49 participants)\n",
    "hm_mask_list = []\n",
    "for sub in hm_subs:\n",
    "    mask = os.path.join(mask_dir, 'func_sub'+str(sub)+'_mask_stereonl.nii')\n",
    "    hm_mask_list.append(mask)\n",
    "print(len(hm_mask_list))    \n",
    "grp_mask_hm = masking.intersect_masks(mask_imgs = hm_mask_list, threshold=0.50, connected=True)    \n",
    "\n",
    "# plotting.plot_roi(roi_img=grp_mask_hm, bg_img=anat, cut_coords=(0, -7, -7), cmap='Paired')\n",
    "#plotting.view_img(grp_mask_hm, bg_img=anat, resampling_interpolation='nearest')\n",
    "\n",
    "# Correct Source versus Wrong Source (49 participants)\n",
    "cw_mask_list = []\n",
    "for sub in cw_subs:\n",
    "    mask = os.path.join(mask_dir, 'func_sub'+str(sub)+'_mask_stereonl.nii')\n",
    "    cw_mask_list.append(mask)\n",
    "print(len(cw_mask_list))    \n",
    "grp_mask_cw = masking.intersect_masks(mask_imgs = cw_mask_list, threshold=0.50, connected=True)    \n",
    "\n",
    "# plotting.plot_roi(roi_img=grp_mask_cw, bg_img=anat, cut_coords=(0, -7, -7), cmap='Paired')\n",
    "#plotting.view_img(grp_mask_cw, bg_img=anat, resampling_interpolation='nearest')\n",
    "\n",
    "\n",
    "# Correct Source versus Miss (38 participants)\n",
    "cmiss_mask_list = []\n",
    "for sub in cmiss_subs:\n",
    "    mask = os.path.join(mask_dir, 'func_sub'+str(sub)+'_mask_stereonl.nii')\n",
    "    cmiss_mask_list.append(mask)\n",
    "print(len(cmiss_mask_list))    \n",
    "grp_mask_cmiss = masking.intersect_masks(mask_imgs = cmiss_mask_list, threshold=0.50, connected=True)    \n",
    "\n",
    "# plotting.plot_roi(roi_img=grp_mask_cw, bg_img=anat, cut_coords=(0, -7, -7), cmap='Paired')\n",
    "# plotting.view_img(grp_mask_cmiss, bg_img=anat, resampling_interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: For each categorization, randomly assign and split participants into a training set and a test set.\n",
    "\n",
    "Note: stratify to maintain comparable proportions of Cognitively Normal (Controls), Subjective Cognitive Disorder (SCD) and Mild Cognitive Impairment (MCI) participants between the testing and training sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encoding vs Control Task Conditions\n",
    "enc_ctl_train, enc_ctl_test, y_enc_ctl_train, y_enc_ctl_test = train_test_split(\n",
    "    all_subs, # list of subjects to split\n",
    "    all_memScore, # list of scores to split\n",
    "    test_size = 0.4, # 60%/40% split between train and test\n",
    "    shuffle= True, \n",
    "    stratify = all_diagnosis, # keep consistent proportions of Controls, SCDs and MCIs between sets\n",
    "    random_state = 123)\n",
    "\n",
    "print('enc_ctl training subjects:', len(enc_ctl_train),\n",
    "      'enc_ctl training scores:', len(y_enc_ctl_train),\n",
    "      'enc_ctl testing subjects:', len(enc_ctl_test),\n",
    "     'enc_ctl testing scores:', len(y_enc_ctl_test))\n",
    "\n",
    "\n",
    "# Hit vs Miss Trials\n",
    "hit_miss_train, hit_miss_test, y_hit_miss_train, y_hit_miss_test = train_test_split(\n",
    "    hm_subs, # list of subjects to split\n",
    "    hm_memScore, # list of scores to split\n",
    "    test_size = 0.4, # 60%/40% split between train and test\n",
    "    shuffle= True, \n",
    "    stratify = hm_diagnosis, # keep consistent proportions of Controls, SCDs and MCIs between sets\n",
    "    random_state = 52)\n",
    "\n",
    "print('hit_miss training subjects:', len(hit_miss_train),\n",
    "      'hit_miss training scores:', len(y_hit_miss_train),\n",
    "      'hit_miss testing subjects:', len(hit_miss_test),\n",
    "     'hit_miss testing scores:', len(y_hit_miss_test))\n",
    "\n",
    "\n",
    "# Correct Source vs Wrong Source Trials\n",
    "cs_ws_train, cs_ws_test, y_cs_ws_train, y_cs_ws_test = train_test_split(\n",
    "    cw_subs, # list of subjects to split\n",
    "    cw_memScore, # list of scores to split\n",
    "    test_size = 0.4, # 60%/40% split between train and test\n",
    "    shuffle= True, \n",
    "    stratify = cw_diagnosis, # keep consistent proportions of Controls, SCDs and MCIs between sets\n",
    "    random_state = 46)\n",
    "\n",
    "print('cs_ws training subjects:', len(cs_ws_train),\n",
    "      'cs_ws training scores:', len(y_cs_ws_train),\n",
    "      'cs_ws testing subjects:', len(cs_ws_test),\n",
    "     'cs_ws testing scores:', len(y_cs_ws_test))\n",
    "\n",
    "\n",
    "# Correct Source vs Miss Trials\n",
    "\n",
    "cs_miss_train, cs_miss_test, y_cs_miss_train, y_cs_miss_test = train_test_split(\n",
    "    cmiss_subs, # list of subjects to split\n",
    "    cmiss_memScore, # list of scores to split\n",
    "    test_size = 0.4, # 60%/40% split between train and test\n",
    "    shuffle= True, \n",
    "    stratify = cmiss_diagnosis, # keep consistent proportions of Controls, SCDs and MCIs between sets\n",
    "    random_state = 103)\n",
    "\n",
    "print('cs_miss training subjects:', len(cs_miss_train),\n",
    "      'cs_miss training scores:', len(y_cs_miss_train),\n",
    "      'cs_miss testing subjects:', len(cs_miss_test),\n",
    "     'cs_miss testing scores:', len(y_cs_miss_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Build training and testing feature matrices\n",
    "\n",
    "For each participant:\n",
    "- With nilearn's NiftiMasker, vectorize single 3D beta of task contrast (computer in Nistats, 1st level model) to derive features for classification. The NiftiMasker converts 4D beta-images into a 2D a vectorized data matrix (each 3D beta map becomes a 1D vector; rows = trials, columns = voxels) as input for machine learning.\n",
    "Here, a single row of features per participant\n",
    "- concatenate the participant's fmri and label data into two matrices (fmri and labels). There should be two matrices per set (train and test) per analysis.\n",
    "\n",
    "Note: \n",
    "The NiftiMasker converts 4D beta-images into a 2D a vectorized data matrix (each 3D beta map becomes a 1D vector; rows = trials, columns = voxels) as input for machine learning.\n",
    "\n",
    "Masking: using a group mask built from the intersection of normalized functional MRI data masks (outputted by NIAK), to determine which voxels to include in the final data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to directories of interest\n",
    "beta_dir = '/Users/mombot/Documents/Simexp/CIMAQ/Data/Nistats/Betas'\n",
    "\n",
    "\n",
    "# ENCODING VERSUS CONTROL TASK CONTRAST\n",
    "\n",
    "#####TO FIX!!!\n",
    "\n",
    "# For each set (training and test), create an empty numpy array to store \n",
    "# concatenated vectorized beta maps (one row per trial; size = trials * voxels).\n",
    "# 1. determine the number of rows needed (sum of trials per participants in set)\n",
    "numrow_train = 0\n",
    "numrow_test = 0\n",
    "for sub in enc_ctl_train:\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_enco_ctl.tsv')\n",
    "    y_enco_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    numrow_train = numrow_train + y_enco_ctl.shape[0]\n",
    "\n",
    "for sub in enc_ctl_test:\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_enco_ctl.tsv')\n",
    "    y_enco_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    numrow_test = numrow_test + y_enco_ctl.shape[0]    \n",
    "    \n",
    "print('number of trials in the training set: ', numrow_train,\n",
    "     'number of trials in the test set: ', numrow_test)    \n",
    "\n",
    "# 2. determine the number of columns needed (voxels in the vectorized group mask)\n",
    "masker = NiftiMasker(mask_img=grp_mask_all, standardize=False)\n",
    "numvox = masker.fit_transform(grp_mask_all).shape[1]\n",
    "\n",
    "# 3. create an empty numpy array to store the data \n",
    "X_enc_ctl_train = np.empty(shape=(numrow_train, numvox))\n",
    "X_enc_ctl_test = np.empty(shape=(numrow_test, numvox))\n",
    "# X_enc_ctl_train = np.zeros(shape=(0, numvox))\n",
    "# X_enc_ctl_test = np.zeros(shape=(0, numvox))\n",
    "\n",
    "print(X_enc_ctl_train.shape, X_enc_ctl_test.shape)\n",
    "\n",
    "# 4. create empty dataframes to store trial labels (one per set)\n",
    "y_enc_ctl_train = pd.DataFrame()\n",
    "y_enc_ctl_train.insert(loc = 0, column = 'condition', value = 'TBD', allow_duplicates=True)\n",
    "y_enc_ctl_train.insert(loc = 1, column = 'dccid', value = 'TBD', allow_duplicates=True)\n",
    "y_enc_ctl_train.insert(loc = 2, column = 'trialnum', value = 'NaN', allow_duplicates=True)\n",
    "\n",
    "y_enc_ctl_test = y_enc_ctl_train.copy()\n",
    "\n",
    "# 5. Create a masker object to vectorize beta maps; \n",
    "# one map per trial becomes its own row in X_data matrix\n",
    "enc_ctl_masker = NiftiMasker(mask_img=grp_mask_all, standardize=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
