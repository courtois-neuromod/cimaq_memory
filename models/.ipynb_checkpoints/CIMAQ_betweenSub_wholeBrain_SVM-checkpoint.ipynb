{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between-subject SVM classification based on entire brain's voxels for CIMAQ memory encoding task (fMRI data).\n",
    "Trials (conditions) are classifierd according to:\n",
    "- task condition (encoding or control task)\n",
    "- memory performance (hit vs miss, correct vs incorrect source)\n",
    "- stimulus category (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nilearn\n",
    "import scipy\n",
    "import nibabel as nb\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from numpy import nan as NaN\n",
    "from matplotlib import pyplot as plt\n",
    "from nilearn import image, plotting\n",
    "from nilearn import masking\n",
    "from nilearn import plotting\n",
    "from nilearn import datasets\n",
    "from nilearn.plotting import plot_stat_map, plot_roi, plot_anat, plot_img, show\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, f1_score\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: import list of participants, and generate sublists of participants who have enough trials per category for each classification\n",
    "\n",
    "1. Encoding vs Control task conditions (all 94)\n",
    "\n",
    "2. Stimulus category (all 94)\n",
    "\n",
    "3. Hit versus Miss (42 participants; at least 15 trials per condition)\n",
    "\n",
    "4. Correct Source versus Wrong Source (49 participants; at least 15 trials per condition)\n",
    "\n",
    "5. Correct Source versus Miss (38 participants; at least 15 trials per condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      108391\n",
      "1      120839\n",
      "2      122922\n",
      "3      127228\n",
      "4      139593\n",
      "6      147863\n",
      "7      150649\n",
      "8      164965\n",
      "9      175295\n",
      "10     178101\n",
      "11     189005\n",
      "12     197192\n",
      "14     199801\n",
      "15     219637\n",
      "16     229301\n",
      "17     247659\n",
      "18     254402\n",
      "19     255499\n",
      "20     258618\n",
      "21     258912\n",
      "22     267168\n",
      "23     270218\n",
      "24     271596\n",
      "27     314409\n",
      "28     326073\n",
      "29     336665\n",
      "30     337021\n",
      "31     350555\n",
      "32     370092\n",
      "34     385370\n",
      "        ...  \n",
      "70     763590\n",
      "71     778749\n",
      "72     783781\n",
      "73     785217\n",
      "74     785245\n",
      "75     804743\n",
      "77     845675\n",
      "78     866812\n",
      "79     878354\n",
      "80     884343\n",
      "81     886007\n",
      "83     893978\n",
      "85     901551\n",
      "86     906145\n",
      "87     914042\n",
      "88     915022\n",
      "89     920577\n",
      "90     932933\n",
      "91     936730\n",
      "92     938001\n",
      "93     955548\n",
      "94     956049\n",
      "95     956130\n",
      "96     968913\n",
      "97     974246\n",
      "98     979001\n",
      "99     983291\n",
      "100    988602\n",
      "101    996599\n",
      "102    998166\n",
      "Name: participant_id, Length: 94, dtype: int64\n",
      "94\n",
      "0      108391\n",
      "2      122922\n",
      "4      139593\n",
      "8      164965\n",
      "14     199801\n",
      "17     247659\n",
      "19     255499\n",
      "20     258618\n",
      "21     258912\n",
      "24     271596\n",
      "27     314409\n",
      "29     336665\n",
      "30     337021\n",
      "36     396250\n",
      "37     403131\n",
      "38     408506\n",
      "39     413474\n",
      "41     437101\n",
      "42     439776\n",
      "44     458807\n",
      "45     459801\n",
      "47     484204\n",
      "49     502616\n",
      "55     567214\n",
      "56     597569\n",
      "60     652850\n",
      "65     677561\n",
      "66     711830\n",
      "67     729722\n",
      "68     739694\n",
      "69     748676\n",
      "70     763590\n",
      "71     778749\n",
      "72     783781\n",
      "80     884343\n",
      "81     886007\n",
      "89     920577\n",
      "91     936730\n",
      "95     956130\n",
      "97     974246\n",
      "99     983291\n",
      "102    998166\n",
      "Name: participant_id, dtype: int64\n",
      "42\n",
      "0      108391\n",
      "2      122922\n",
      "4      139593\n",
      "7      150649\n",
      "9      175295\n",
      "10     178101\n",
      "12     197192\n",
      "14     199801\n",
      "16     229301\n",
      "20     258618\n",
      "22     267168\n",
      "28     326073\n",
      "29     336665\n",
      "30     337021\n",
      "31     350555\n",
      "34     385370\n",
      "38     408506\n",
      "39     413474\n",
      "40     427357\n",
      "41     437101\n",
      "44     458807\n",
      "45     459801\n",
      "46     462345\n",
      "49     502616\n",
      "53     549994\n",
      "54     555537\n",
      "55     567214\n",
      "57     619278\n",
      "60     652850\n",
      "62     659068\n",
      "64     668786\n",
      "65     677561\n",
      "66     711830\n",
      "68     739694\n",
      "69     748676\n",
      "71     778749\n",
      "72     783781\n",
      "79     878354\n",
      "80     884343\n",
      "83     893978\n",
      "85     901551\n",
      "86     906145\n",
      "88     915022\n",
      "90     932933\n",
      "91     936730\n",
      "92     938001\n",
      "93     955548\n",
      "96     968913\n",
      "101    996599\n",
      "Name: participant_id, dtype: int64\n",
      "49\n",
      "0      108391\n",
      "2      122922\n",
      "4      139593\n",
      "8      164965\n",
      "14     199801\n",
      "17     247659\n",
      "19     255499\n",
      "20     258618\n",
      "24     271596\n",
      "27     314409\n",
      "29     336665\n",
      "30     337021\n",
      "36     396250\n",
      "37     403131\n",
      "38     408506\n",
      "39     413474\n",
      "41     437101\n",
      "42     439776\n",
      "44     458807\n",
      "45     459801\n",
      "47     484204\n",
      "49     502616\n",
      "55     567214\n",
      "56     597569\n",
      "60     652850\n",
      "65     677561\n",
      "66     711830\n",
      "67     729722\n",
      "68     739694\n",
      "69     748676\n",
      "71     778749\n",
      "72     783781\n",
      "80     884343\n",
      "81     886007\n",
      "91     936730\n",
      "95     956130\n",
      "99     983291\n",
      "102    998166\n",
      "Name: participant_id, dtype: int64\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# Path to directory with participant lists\n",
    "data_file = '/Users/mombot/Documents/Simexp/CIMAQ/Data/Participants/Splitting/Sub_list.tsv'\n",
    "sub_data = pd.read_csv(data_file, sep = '\\t')\n",
    "\n",
    "# Exclude participants who failed QC\n",
    "sub_data = sub_data[sub_data['QC_status']!= 'F']\n",
    "\n",
    "# Set minimal number of trials needed per subject to include them in analysis\n",
    "num = 14\n",
    "\n",
    "# Encoding vs Control, and Stimulus Category classifications\n",
    "all_subs = sub_data['participant_id']\n",
    "all_diagnosis = sub_data['cognitive_status']\n",
    "print(all_subs)\n",
    "print(len(all_subs))\n",
    "\n",
    "# Hit versus Miss\n",
    "hm_data = sub_data[sub_data['hits'] > num]\n",
    "hm_data = hm_data[hm_data['miss'] > num]\n",
    "hm_subs = hm_data['participant_id']\n",
    "hm_diagnosis = hm_data['cognitive_status']\n",
    "print(hm_subs)\n",
    "print(len(hm_subs))\n",
    "\n",
    "# Correct Source versus Wrong Source \n",
    "cw_data = sub_data[sub_data['correct_source'] > num]\n",
    "cw_data = cw_data[cw_data['wrong_source'] > num]\n",
    "cw_subs = cw_data['participant_id']\n",
    "cw_diagnosis = cw_data['cognitive_status']\n",
    "print(cw_subs)\n",
    "print(len(cw_subs))\n",
    "\n",
    "# Correct Source versus Miss\n",
    "cmiss_data = sub_data[sub_data['correct_source'] > num]\n",
    "cmiss_data = cmiss_data[cmiss_data['miss'] > num]\n",
    "cmiss_subs = cmiss_data['participant_id']\n",
    "cmiss_diagnosis = cmiss_data['cognitive_status']\n",
    "print(cmiss_subs)\n",
    "print(len(cmiss_subs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: For each subject list (analysis), create a group mask from individual functional mri masks.  \n",
    "\n",
    "The mask should only include voxels included in all participants's individual functional mask (intersection). The mask will serve to vectorize 3D beta weigths maps into feature rows. \n",
    "\n",
    "**Update: use 0.5 treshold, otherwise too much signal drop out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "42\n",
      "49\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# Anatomical template for display\n",
    "anat = '/Users/mombot/Documents/Simexp/CIMAQ/Data/Templates/template_anat_stereo.nii'\n",
    "\n",
    "# Path to directory with masks\n",
    "mask_dir = '/Users/mombot/Documents/Simexp/CIMAQ/Data/masks'\n",
    "\n",
    "# All participants (94 participants)\n",
    "all_mask_list = []\n",
    "for sub in all_subs:\n",
    "    mask = os.path.join(mask_dir, 'func_sub'+str(sub)+'_mask_stereonl.nii')\n",
    "    all_mask_list.append(mask)\n",
    "print(len(all_mask_list))    \n",
    "grp_mask_all = masking.intersect_masks(mask_imgs = all_mask_list, threshold=0.5, connected=True)    \n",
    "\n",
    "# plotting.plot_roi(roi_img=grp_mask_all, bg_img=anat, cut_coords=(0, -7, -7), cmap='Paired')\n",
    "#plotting.view_img(grp_mask_all, bg_img=anat, resampling_interpolation='nearest')\n",
    "\n",
    "# Hit versus miss (49 participants)\n",
    "hm_mask_list = []\n",
    "for sub in hm_subs:\n",
    "    mask = os.path.join(mask_dir, 'func_sub'+str(sub)+'_mask_stereonl.nii')\n",
    "    hm_mask_list.append(mask)\n",
    "print(len(hm_mask_list))    \n",
    "grp_mask_hm = masking.intersect_masks(mask_imgs = hm_mask_list, threshold=0.50, connected=True)    \n",
    "\n",
    "# plotting.plot_roi(roi_img=grp_mask_hm, bg_img=anat, cut_coords=(0, -7, -7), cmap='Paired')\n",
    "#plotting.view_img(grp_mask_hm, bg_img=anat, resampling_interpolation='nearest')\n",
    "\n",
    "# Correct Source versus Wrong Source (49 participants)\n",
    "cw_mask_list = []\n",
    "for sub in cw_subs:\n",
    "    mask = os.path.join(mask_dir, 'func_sub'+str(sub)+'_mask_stereonl.nii')\n",
    "    cw_mask_list.append(mask)\n",
    "print(len(cw_mask_list))    \n",
    "grp_mask_cw = masking.intersect_masks(mask_imgs = cw_mask_list, threshold=0.50, connected=True)    \n",
    "\n",
    "# plotting.plot_roi(roi_img=grp_mask_cw, bg_img=anat, cut_coords=(0, -7, -7), cmap='Paired')\n",
    "#plotting.view_img(grp_mask_cw, bg_img=anat, resampling_interpolation='nearest')\n",
    "\n",
    "\n",
    "# Correct Source versus Miss (38 participants)\n",
    "cmiss_mask_list = []\n",
    "for sub in cmiss_subs:\n",
    "    mask = os.path.join(mask_dir, 'func_sub'+str(sub)+'_mask_stereonl.nii')\n",
    "    cmiss_mask_list.append(mask)\n",
    "print(len(cmiss_mask_list))    \n",
    "grp_mask_cmiss = masking.intersect_masks(mask_imgs = cmiss_mask_list, threshold=0.50, connected=True)    \n",
    "\n",
    "# plotting.plot_roi(roi_img=grp_mask_cw, bg_img=anat, cut_coords=(0, -7, -7), cmap='Paired')\n",
    "# plotting.view_img(grp_mask_cmiss, bg_img=anat, resampling_interpolation='nearest')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: For each categorization, randomly assign and split participants into \n",
    "a **training** set and a **test** set\n",
    "\n",
    "Note: stratify to maintain comparable proportions of Cognitively Normal (Controls), Subjective Cognitive Disorder (SCD) and Mild Cognitive Impairment (MCI) participants between the testing and training sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_ctl training: 56 enc_ctl testing: 38\n",
      "hit_miss training: 25 hit_miss testing: 17\n",
      "cs_ws training: 29 cs_ws testing: 20\n",
      "cs_miss training: 22 cs_miss testing: 16\n"
     ]
    }
   ],
   "source": [
    "# Encoding vs Control Task Conditions\n",
    "\n",
    "enc_ctl_train, enc_ctl_test = train_test_split(\n",
    "    all_subs, # list to split\n",
    "    test_size = 0.4, # 60%/40% split between train and test\n",
    "    shuffle= True, \n",
    "    stratify = all_diagnosis, # keep consistent proportions of Controls, SCDs and MCIs between sets\n",
    "    random_state = 123)\n",
    "\n",
    "print('enc_ctl training:', len(enc_ctl_train),\n",
    "     'enc_ctl testing:', len(enc_ctl_test))\n",
    "\n",
    "\n",
    "# Hit vs Miss Trials\n",
    "\n",
    "hit_miss_train, hit_miss_test = train_test_split(\n",
    "    hm_subs, # list to split\n",
    "    test_size = 0.4, # 60%/40% split between train and test\n",
    "    shuffle= True, \n",
    "    stratify = hm_diagnosis, # keep consistent proportions of Controls, SCDs and MCIs between sets\n",
    "    random_state = 52)\n",
    "\n",
    "print('hit_miss training:', len(hit_miss_train),\n",
    "     'hit_miss testing:', len(hit_miss_test))\n",
    "\n",
    "\n",
    "# Correct Source vs Wrong Source Trials\n",
    "\n",
    "cs_ws_train, cs_ws_test = train_test_split(\n",
    "    cw_subs, # list to split\n",
    "    test_size = 0.4, # 60%/40% split between train and test\n",
    "    shuffle= True, \n",
    "    stratify = cw_diagnosis, # keep consistent proportions of Controls, SCDs and MCIs between sets\n",
    "    random_state = 46)\n",
    "\n",
    "print('cs_ws training:', len(cs_ws_train),\n",
    "     'cs_ws testing:', len(cs_ws_test))\n",
    "\n",
    "\n",
    "# Correct Source vs Miss Trials\n",
    "\n",
    "cs_miss_train, cs_miss_test = train_test_split(\n",
    "    cmiss_subs, # list to split\n",
    "    test_size = 0.4, # 60%/40% split between train and test\n",
    "    shuffle= True, \n",
    "    stratify = cmiss_diagnosis, # keep consistent proportions of Controls, SCDs and MCIs between sets\n",
    "    random_state = 103)\n",
    "\n",
    "print('cs_miss training:', len(cs_miss_train),\n",
    "     'cs_miss testing:', len(cs_miss_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Build training and testing feature matrices\n",
    "\n",
    "For each participant:\n",
    "- vectorize 3D beta maps (loaded in temporal order) with nilearn's NiftiMasker to derive features for classification. The NiftiMasker converts 4D beta-images into a 2D a vectorized data matrix (each 3D beta map becomes a 1D vector; rows = trials, columns = voxels) as input for machine learning.\n",
    "- load the trial labels\n",
    "- mask the data (fmri and labels) that correspond to trials of interest\n",
    "- concatenate the participant's fmri and label data into two matrices (fmri and labels). There should be two matrices per set (train and test) per analysis.\n",
    "\n",
    "Note: \n",
    "The NiftiMasker converts 4D beta-images into a 2D a vectorized data matrix (each 3D beta map becomes a 1D vector; rows = trials, columns = voxels) as input for machine learning.\n",
    "\n",
    "Masking: using a group mask built from the intersection of normalized functional MRI data masks (outputted by NIAK), to determine which voxels to include in the final data matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to directories of interest\n",
    "beta_dir = '/Users/mombot/Documents/Simexp/CIMAQ/Data/Nistats/Betas'\n",
    "label_dir = '/Users/mombot/Documents/Simexp/CIMAQ/Data/Nistats/Events'\n",
    "output_dir = '/Users/mombot/Documents/Simexp/CIMAQ/Data/Nilearn/features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trials in the training set:  6526 number of trials in the test set:  4420\n",
      "(6526, 70015) (4420, 70015)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ENCODING VERSUS CONTROL TASK CLASSIFICATION\n",
    "\n",
    "# For each set (training and test), create an empty numpy array to store \n",
    "# concatenated vectorized beta maps (one row per trial; size = trials * voxels).\n",
    "# 1. determine the number of rows needed (sum of trials per participants in set)\n",
    "numrow_train = 0\n",
    "numrow_test = 0\n",
    "for sub in enc_ctl_train:\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_enco_ctl.tsv')\n",
    "    y_enco_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    numrow_train = numrow_train + y_enco_ctl.shape[0]\n",
    "\n",
    "for sub in enc_ctl_test:\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_enco_ctl.tsv')\n",
    "    y_enco_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    numrow_test = numrow_test + y_enco_ctl.shape[0]    \n",
    "    \n",
    "print('number of trials in the training set: ', numrow_train,\n",
    "     'number of trials in the test set: ', numrow_test)    \n",
    "\n",
    "# 2. determine the number of columns needed (voxels in the vectorized group mask)\n",
    "masker = NiftiMasker(mask_img=grp_mask_all, standardize=False)\n",
    "numvox = masker.fit_transform(grp_mask_all).shape[1]\n",
    "\n",
    "# 3. create an empty numpy array to store the data \n",
    "X_enc_ctl_train = np.empty(shape=(numrow_train, numvox))\n",
    "X_enc_ctl_test = np.empty(shape=(numrow_test, numvox))\n",
    "# X_enc_ctl_train = np.zeros(shape=(0, numvox))\n",
    "# X_enc_ctl_test = np.zeros(shape=(0, numvox))\n",
    "\n",
    "print(X_enc_ctl_train.shape, X_enc_ctl_test.shape)\n",
    "\n",
    "# 4. create empty dataframes to store trial labels (one per set)\n",
    "y_enc_ctl_train = pd.DataFrame()\n",
    "y_enc_ctl_train.insert(loc = 0, column = 'condition', value = 'TBD', allow_duplicates=True)\n",
    "y_enc_ctl_train.insert(loc = 1, column = 'dccid', value = 'TBD', allow_duplicates=True)\n",
    "y_enc_ctl_train.insert(loc = 2, column = 'trialnum', value = 'NaN', allow_duplicates=True)\n",
    "\n",
    "y_enc_ctl_test = y_enc_ctl_train.copy()\n",
    "\n",
    "# 5. Create a masker object to vectorize beta maps; \n",
    "# one map per trial becomes its own row in X_data matrix\n",
    "enc_ctl_masker = NiftiMasker(mask_img=grp_mask_all, standardize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878354\n",
      "number of X filled rows:  117 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (117, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "955548\n",
      "number of X filled rows:  234 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (234, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "983291\n",
      "number of X filled rows:  351 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (351, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "968913\n",
      "number of X filled rows:  468 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (468, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "956049\n",
      "number of X filled rows:  585 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (585, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "893978\n",
      "number of X filled rows:  702 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (702, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "258912\n",
      "number of X filled rows:  815 subject X_shape: (113, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (113, 3) total y_shape: (815, 3)\n",
      "Enc    74\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "628299\n",
      "number of X filled rows:  932 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (932, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "711830\n",
      "number of X filled rows:  1049 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1049, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "267168\n",
      "number of X filled rows:  1166 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1166, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "543589\n",
      "number of X filled rows:  1281 subject X_shape: (115, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (115, 3) total y_shape: (1281, 3)\n",
      "Enc    76\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "484204\n",
      "number of X filled rows:  1398 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1398, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "668786\n",
      "number of X filled rows:  1511 subject X_shape: (113, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (113, 3) total y_shape: (1511, 3)\n",
      "Enc    74\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "748676\n",
      "number of X filled rows:  1628 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1628, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "549994\n",
      "number of X filled rows:  1745 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1745, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "845675\n",
      "number of X filled rows:  1862 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1862, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "974246\n",
      "number of X filled rows:  1979 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1979, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "189005\n",
      "number of X filled rows:  2096 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2096, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "520377\n",
      "number of X filled rows:  2211 subject X_shape: (115, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (115, 3) total y_shape: (2211, 3)\n",
      "Enc    76\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "408506\n",
      "number of X filled rows:  2328 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2328, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "439776\n",
      "number of X filled rows:  2445 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2445, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "490035\n",
      "number of X filled rows:  2562 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2562, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "739694\n",
      "number of X filled rows:  2679 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2679, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "326073\n",
      "number of X filled rows:  2796 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2796, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "785217\n",
      "number of X filled rows:  2913 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2913, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "920577\n",
      "number of X filled rows:  3030 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3030, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "270218\n",
      "number of X filled rows:  3147 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3147, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "785245\n",
      "number of X filled rows:  3264 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3264, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "437101\n",
      "number of X filled rows:  3381 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3381, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "254402\n",
      "number of X filled rows:  3498 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3498, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "219637\n",
      "number of X filled rows:  3615 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3615, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "988602\n",
      "number of X filled rows:  3732 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3732, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "597569\n",
      "number of X filled rows:  3849 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3849, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "258618\n",
      "number of X filled rows:  3966 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3966, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "413474\n",
      "number of X filled rows:  4083 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (4083, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "139593\n",
      "number of X filled rows:  4200 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (4200, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "936730\n",
      "number of X filled rows:  4315 subject X_shape: (115, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (115, 3) total y_shape: (4315, 3)\n",
      "Enc    76\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "459801\n",
      "number of X filled rows:  4432 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (4432, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "783781\n",
      "number of X filled rows:  4549 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (4549, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "998166\n",
      "number of X filled rows:  4662 subject X_shape: (113, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (113, 3) total y_shape: (4662, 3)\n",
      "Enc    74\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "914042\n",
      "number of X filled rows:  4779 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (4779, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "386333\n",
      "number of X filled rows:  4896 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (4896, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "127228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of X filled rows:  5013 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (5013, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "763590\n",
      "number of X filled rows:  5126 subject X_shape: (113, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (113, 3) total y_shape: (5126, 3)\n",
      "Enc    75\n",
      "CTL    38\n",
      "Name: condition, dtype: int64\n",
      "884343\n",
      "number of X filled rows:  5243 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (5243, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "652850\n",
      "number of X filled rows:  5360 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (5360, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "956130\n",
      "number of X filled rows:  5477 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (5477, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "502616\n",
      "number of X filled rows:  5594 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (5594, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "147863\n",
      "number of X filled rows:  5711 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (5711, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "175295\n",
      "number of X filled rows:  5828 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (5828, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "403131\n",
      "number of X filled rows:  5945 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (5945, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "901551\n",
      "number of X filled rows:  6060 subject X_shape: (115, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (115, 3) total y_shape: (6060, 3)\n",
      "Enc    76\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "122922\n",
      "number of X filled rows:  6177 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (6177, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "255499\n",
      "number of X filled rows:  6292 subject X_shape: (115, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (115, 3) total y_shape: (6292, 3)\n",
      "Enc    76\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "555537\n",
      "number of X filled rows:  6409 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (6409, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "906145\n",
      "number of X filled rows:  6526 subject X_shape: (117, 70015) total X_shape: (6526, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (6526, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "The training data set is built!\n",
      "729722\n",
      "number of X filled rows:  117 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (117, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "441008\n",
      "number of X filled rows:  234 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (234, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "271596\n",
      "number of X filled rows:  347 subject X_shape: (113, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (113, 3) total y_shape: (347, 3)\n",
      "Enc    74\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "659068\n",
      "number of X filled rows:  464 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (464, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "778749\n",
      "number of X filled rows:  581 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (581, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "385370\n",
      "number of X filled rows:  698 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (698, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "938001\n",
      "number of X filled rows:  815 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (815, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "458807\n",
      "number of X filled rows:  932 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (932, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "247659\n",
      "number of X filled rows:  1041 subject X_shape: (109, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (109, 3) total y_shape: (1041, 3)\n",
      "Enc    71\n",
      "CTL    38\n",
      "Name: condition, dtype: int64\n",
      "120839\n",
      "number of X filled rows:  1158 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1158, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "336665\n",
      "number of X filled rows:  1271 subject X_shape: (113, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (113, 3) total y_shape: (1271, 3)\n",
      "Enc    75\n",
      "CTL    38\n",
      "Name: condition, dtype: int64\n",
      "886007\n",
      "number of X filled rows:  1388 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1388, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "567214\n",
      "number of X filled rows:  1505 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1505, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "804743\n",
      "number of X filled rows:  1622 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1622, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "199801\n",
      "number of X filled rows:  1739 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1739, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "150649\n",
      "number of X filled rows:  1856 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1856, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "337021\n",
      "number of X filled rows:  1973 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (1973, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "197192\n",
      "number of X filled rows:  2090 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2090, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "630120\n",
      "number of X filled rows:  2207 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2207, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "314409\n",
      "number of X filled rows:  2324 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2324, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "350555\n",
      "number of X filled rows:  2441 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2441, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "178101\n",
      "number of X filled rows:  2558 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2558, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "979001\n",
      "number of X filled rows:  2675 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2675, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "427357\n",
      "number of X filled rows:  2792 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2792, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "396250\n",
      "number of X filled rows:  2909 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (2909, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "658178\n",
      "number of X filled rows:  3026 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3026, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "866812\n",
      "number of X filled rows:  3143 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3143, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "517070\n",
      "number of X filled rows:  3260 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3260, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "619278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of X filled rows:  3377 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3377, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "229301\n",
      "number of X filled rows:  3490 subject X_shape: (113, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (113, 3) total y_shape: (3490, 3)\n",
      "Enc    75\n",
      "CTL    38\n",
      "Name: condition, dtype: int64\n",
      "932933\n",
      "number of X filled rows:  3607 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3607, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "108391\n",
      "number of X filled rows:  3724 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3724, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "462345\n",
      "number of X filled rows:  3839 subject X_shape: (115, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (115, 3) total y_shape: (3839, 3)\n",
      "Enc    76\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "915022\n",
      "number of X filled rows:  3956 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (3956, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "370092\n",
      "number of X filled rows:  4069 subject X_shape: (113, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (113, 3) total y_shape: (4069, 3)\n",
      "Enc    74\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "677561\n",
      "number of X filled rows:  4186 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (4186, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "164965\n",
      "number of X filled rows:  4303 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (4303, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "996599\n",
      "number of X filled rows:  4420 subject X_shape: (117, 70015) total X_shape: (4420, 70015)\n",
      "subject y_shape: (117, 3) total y_shape: (4420, 3)\n",
      "Enc    78\n",
      "CTL    39\n",
      "Name: condition, dtype: int64\n",
      "The testing data set is built!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. Fill the X (beta weights per voxel) and y (trial labels) data matrices\n",
    "\n",
    "# note: nilearn.image.load_img concatenates 3D beta maps in alphabetical order\n",
    "# trial numbers must be PADDED with zeros to preserve their temporal order when alphabetized\n",
    "\n",
    "# TRAINING SET\n",
    "j = 0\n",
    "for sub in enc_ctl_train: \n",
    "    print(sub)\n",
    "    betas = image.load_img(img=os.path.join(beta_dir, str(sub), 'TrialContrasts/betas_sub'+str(sub)+'*.nii'),\n",
    "                           wildcards=True)\n",
    "    sub_trials = enc_ctl_masker.fit_transform(betas)\n",
    "    X_enc_ctl_train[j:(j+sub_trials.shape[0]), :] = sub_trials\n",
    "    j = j + sub_trials.shape[0]\n",
    "    #X_enc_ctl_train = np.append(X_enc_ctl_train, sub_trials, axis = 0)\n",
    "    print('number of X filled rows: ', j, \n",
    "          'subject X_shape:', sub_trials.shape,\n",
    "         'total X_shape:', X_enc_ctl_train.shape)\n",
    "    \n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_enco_ctl.tsv')\n",
    "    y_enco_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    trialnum = y_enco_ctl.index\n",
    "    y_enco_ctl.insert(loc = y_enco_ctl.shape[1], column = 'dccid', \n",
    "                           value = sub, allow_duplicates=True)\n",
    "    y_enco_ctl.insert(loc = y_enco_ctl.shape[1], column = 'trialnum', \n",
    "                           value = trialnum+1, allow_duplicates=True)\n",
    "    y_enc_ctl_train= y_enc_ctl_train.append(y_enco_ctl, ignore_index=True)\n",
    "    print('subject y_shape:', y_enco_ctl.shape,\n",
    "         'total y_shape:', y_enc_ctl_train.shape)\n",
    "    print(y_enco_ctl.condition.value_counts())\n",
    "\n",
    "print('The training data set is built!') \n",
    "\n",
    "# TESTING SET\n",
    "j = 0\n",
    "for sub in enc_ctl_test: \n",
    "    print(sub)\n",
    "    betas = image.load_img(img=os.path.join(beta_dir, str(sub), 'TrialContrasts/betas_sub'+str(sub)+'*.nii'),\n",
    "                           wildcards=True)\n",
    "    sub_trials = enc_ctl_masker.fit_transform(betas)\n",
    "    X_enc_ctl_test[j:(j+sub_trials.shape[0]), :] = sub_trials\n",
    "    j = j + sub_trials.shape[0]\n",
    "    #X_enc_ctl_test = np.append(X_enc_ctl_train, sub_trials, axis = 0)\n",
    "    print('number of X filled rows: ', j, \n",
    "          'subject X_shape:', sub_trials.shape,\n",
    "         'total X_shape:', X_enc_ctl_test.shape)\n",
    "    \n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_enco_ctl.tsv')\n",
    "    y_enco_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    trialnum = y_enco_ctl.index\n",
    "    y_enco_ctl.insert(loc = y_enco_ctl.shape[1], column = 'dccid', \n",
    "                           value = sub, allow_duplicates=True)\n",
    "    y_enco_ctl.insert(loc = y_enco_ctl.shape[1], column = 'trialnum', \n",
    "                           value = trialnum+1, allow_duplicates=True)\n",
    "    y_enc_ctl_test= y_enc_ctl_test.append(y_enco_ctl, ignore_index=True)\n",
    "    print('subject y_shape:', y_enco_ctl.shape,\n",
    "         'total y_shape:', y_enc_ctl_test.shape)\n",
    "    print(y_enco_ctl.condition.value_counts())\n",
    "\n",
    "print('The testing data set is built!') \n",
    "\n",
    "# 7. extract the label columns from the y data dataframes (to input model)\n",
    "y_enco_ctl_labels_train = y_enc_ctl_train['condition']\n",
    "y_enco_ctl_labels_test = y_enc_ctl_test['condition']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trials in the training set:  1928 number of trials in the test set:  1319\n",
      "(1928, 69835) (1319, 69835)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# HITS VERSUS MISS TRIAL CLASSIFICATION\n",
    "\n",
    "## Important: keep only the trials of interest (HIT or MISSED, not CONTROL)\n",
    "## To filter trials, create a mask from the labels column (extracted from labels file)\n",
    "## Apply this mask to the 2D fMRI data matrix: keep only hit or missed trials (rows)\n",
    "## Apply the same mask to the labels matrix (exclude labels of no interest)\n",
    "\n",
    "# For each set (training and test), create an empty numpy array to store \n",
    "# concatenated vectorized beta maps (one row per trial; size = trials * voxels).\n",
    "# 1. determine the number of rows needed (sum of trials per participants in set)\n",
    "numrow_train = 0\n",
    "numrow_test = 0\n",
    "for sub in hit_miss_train:\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_ctl_miss_hit.tsv')\n",
    "    y_hit_miss_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    y_hit_miss_ctl_labels = y_hit_miss_ctl['ctl_miss_hit']\n",
    "    hit_miss_mask = y_hit_miss_ctl_labels.isin(['hit', 'missed'])\n",
    "    y_hit_miss = y_hit_miss_ctl[hit_miss_mask]\n",
    "    numrow_train = numrow_train + y_hit_miss.shape[0]\n",
    "\n",
    "for sub in hit_miss_test:\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_ctl_miss_hit.tsv')\n",
    "    y_hit_miss_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    y_hit_miss_ctl_labels = y_hit_miss_ctl['ctl_miss_hit']\n",
    "    hit_miss_mask = y_hit_miss_ctl_labels.isin(['hit', 'missed'])\n",
    "    y_hit_miss = y_hit_miss_ctl[hit_miss_mask]\n",
    "    numrow_test = numrow_test + y_hit_miss.shape[0]    \n",
    "    \n",
    "print('number of trials in the training set: ', numrow_train,\n",
    "     'number of trials in the test set: ', numrow_test)     \n",
    "\n",
    "# 2. determine the number of columns needed (voxels in the vectorized group mask)\n",
    "masker = NiftiMasker(mask_img=grp_mask_hm, standardize=False)\n",
    "numvox = masker.fit_transform(grp_mask_hm).shape[1]\n",
    "\n",
    "# 3. create an empty numpy array to store the data \n",
    "X_hit_miss_train = np.empty(shape=(numrow_train, numvox))\n",
    "X_hit_miss_test = np.empty(shape=(numrow_test, numvox))\n",
    "\n",
    "print(X_hit_miss_train.shape, X_hit_miss_test.shape)\n",
    "\n",
    "# 4. create empty dataframes to store trial labels (one per set)\n",
    "y_hit_miss_train = pd.DataFrame()\n",
    "y_hit_miss_train.insert(loc = 0, column = 'ctl_miss_hit', value = 'TBD', allow_duplicates=True)\n",
    "y_hit_miss_train.insert(loc = 1, column = 'dccid', value = 'TBD', allow_duplicates=True)\n",
    "y_hit_miss_train.insert(loc = 2, column = 'trialnum', value = 'NaN', allow_duplicates=True)\n",
    "\n",
    "y_hit_miss_test = y_hit_miss_train.copy()\n",
    "\n",
    "# 5. create a masker object to vectorize the beta maps; \n",
    "# one map per trial becomes its own row in X_data matrix\n",
    "hit_miss_masker = NiftiMasker(mask_img=grp_mask_hm, standardize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258912\n",
      "hit       59\n",
      "missed    15\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (74, 3) total y_shape: (74, 3)\n",
      "number of X filled rows:  74 subject X_shape: (74, 69835) total X_shape: (1928, 69835)\n",
      "437101\n",
      "hit       55\n",
      "missed    23\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (152, 3)\n",
      "number of X filled rows:  152 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "920577\n",
      "missed    47\n",
      "hit       31\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (230, 3)\n",
      "number of X filled rows:  230 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "413474\n",
      "hit       58\n",
      "missed    20\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (308, 3)\n",
      "number of X filled rows:  308 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "396250\n",
      "hit       43\n",
      "missed    35\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (386, 3)\n",
      "number of X filled rows:  386 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "936730\n",
      "hit       46\n",
      "missed    30\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (76, 3) total y_shape: (462, 3)\n",
      "number of X filled rows:  462 subject X_shape: (76, 69835) total X_shape: (1928, 69835)\n",
      "652850\n",
      "hit       42\n",
      "missed    36\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (540, 3)\n",
      "number of X filled rows:  540 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "139593\n",
      "missed    41\n",
      "hit       37\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (618, 3)\n",
      "number of X filled rows:  618 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "314409\n",
      "hit       45\n",
      "missed    33\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (696, 3)\n",
      "number of X filled rows:  696 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "502616\n",
      "hit       62\n",
      "missed    16\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (774, 3)\n",
      "number of X filled rows:  774 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "122922\n",
      "hit       55\n",
      "missed    23\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (852, 3)\n",
      "number of X filled rows:  852 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "247659\n",
      "missed    42\n",
      "hit       29\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (71, 3) total y_shape: (923, 3)\n",
      "number of X filled rows:  923 subject X_shape: (71, 69835) total X_shape: (1928, 69835)\n",
      "677561\n",
      "hit       58\n",
      "missed    20\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1001, 3)\n",
      "number of X filled rows:  1001 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "983291\n",
      "hit       60\n",
      "missed    18\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1079, 3)\n",
      "number of X filled rows:  1079 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "408506\n",
      "hit       51\n",
      "missed    27\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1157, 3)\n",
      "number of X filled rows:  1157 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "459801\n",
      "hit       59\n",
      "missed    19\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1235, 3)\n",
      "number of X filled rows:  1235 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "783781\n",
      "hit       61\n",
      "missed    17\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1313, 3)\n",
      "number of X filled rows:  1313 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "336665\n",
      "hit       52\n",
      "missed    23\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (75, 3) total y_shape: (1388, 3)\n",
      "number of X filled rows:  1388 subject X_shape: (75, 69835) total X_shape: (1928, 69835)\n",
      "108391\n",
      "hit       63\n",
      "missed    15\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1466, 3)\n",
      "number of X filled rows:  1466 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "597569\n",
      "hit       60\n",
      "missed    18\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1544, 3)\n",
      "number of X filled rows:  1544 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "956130\n",
      "hit       45\n",
      "missed    33\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1622, 3)\n",
      "number of X filled rows:  1622 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "164965\n",
      "hit       53\n",
      "missed    25\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1700, 3)\n",
      "number of X filled rows:  1700 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "255499\n",
      "hit       49\n",
      "missed    27\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (76, 3) total y_shape: (1776, 3)\n",
      "number of X filled rows:  1776 subject X_shape: (76, 69835) total X_shape: (1928, 69835)\n",
      "403131\n",
      "hit       47\n",
      "missed    31\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1854, 3)\n",
      "number of X filled rows:  1854 subject X_shape: (78, 69835) total X_shape: (1928, 69835)\n",
      "998166\n",
      "hit       46\n",
      "missed    28\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (74, 3) total y_shape: (1928, 3)\n",
      "number of X filled rows:  1928 subject X_shape: (74, 69835) total X_shape: (1928, 69835)\n",
      "The training data set is built!\n",
      "458807\n",
      "hit       53\n",
      "missed    25\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (78, 3)\n",
      "number of X filled rows:  78 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "886007\n",
      "hit       58\n",
      "missed    20\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (156, 3)\n",
      "number of X filled rows:  156 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "763590\n",
      "missed    46\n",
      "hit       29\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (75, 3) total y_shape: (231, 3)\n",
      "number of X filled rows:  231 subject X_shape: (75, 69835) total X_shape: (1319, 69835)\n",
      "778749\n",
      "hit       46\n",
      "missed    32\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (309, 3)\n",
      "number of X filled rows:  309 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "974246\n",
      "missed    46\n",
      "hit       32\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (387, 3)\n",
      "number of X filled rows:  387 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "271596\n",
      "hit       51\n",
      "missed    23\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (74, 3) total y_shape: (461, 3)\n",
      "number of X filled rows:  461 subject X_shape: (74, 69835) total X_shape: (1319, 69835)\n",
      "567214\n",
      "hit       58\n",
      "missed    20\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (539, 3)\n",
      "number of X filled rows:  539 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "711830\n",
      "hit       43\n",
      "missed    35\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (617, 3)\n",
      "number of X filled rows:  617 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "739694\n",
      "hit       58\n",
      "missed    20\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (695, 3)\n",
      "number of X filled rows:  695 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "258618\n",
      "hit       51\n",
      "missed    27\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (773, 3)\n",
      "number of X filled rows:  773 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "199801\n",
      "hit       59\n",
      "missed    19\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (851, 3)\n",
      "number of X filled rows:  851 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "729722\n",
      "hit       54\n",
      "missed    24\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (929, 3)\n",
      "number of X filled rows:  929 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "439776\n",
      "hit       60\n",
      "missed    18\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1007, 3)\n",
      "number of X filled rows:  1007 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "337021\n",
      "hit       61\n",
      "missed    17\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1085, 3)\n",
      "number of X filled rows:  1085 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "884343\n",
      "hit       53\n",
      "missed    25\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1163, 3)\n",
      "number of X filled rows:  1163 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "748676\n",
      "missed    44\n",
      "hit       34\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1241, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of X filled rows:  1241 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "484204\n",
      "hit       50\n",
      "missed    28\n",
      "Name: ctl_miss_hit, dtype: int64\n",
      "subject y_shape: (78, 3) total y_shape: (1319, 3)\n",
      "number of X filled rows:  1319 subject X_shape: (78, 69835) total X_shape: (1319, 69835)\n",
      "The testing data set is built!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. Fill the X (beta weights per voxel) and y (trial labels) data matrices\n",
    "\n",
    "# note: nilearn.image.load_img concatenates 3D beta maps in alphabetical order\n",
    "# trial numbers must be PADDED with zeros to preserve their temporal order when alphabetized\n",
    "\n",
    "# TRAINING SET\n",
    "j = 0\n",
    "for sub in hit_miss_train: \n",
    "    print(sub)\n",
    "    # load labels file as pandas dataframe\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_ctl_miss_hit.tsv')\n",
    "    y_hit_miss_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    \n",
    "    # create a boolean mask to filter out trials of no interest\n",
    "    y_hit_miss_ctl_labels = y_hit_miss_ctl['ctl_miss_hit']\n",
    "    hit_miss_mask = y_hit_miss_ctl_labels.isin(['hit', 'missed'])\n",
    "\n",
    "    # apply mask to labels dataframe to keep only hit and missed trials\n",
    "    y_hit_miss = y_hit_miss_ctl[hit_miss_mask]\n",
    "    \n",
    "    # process and append y data to the set's labels dataframe\n",
    "    trialnum = y_hit_miss.index\n",
    "    y_hit_miss.insert(loc = y_hit_miss.shape[1], column = 'dccid', \n",
    "                           value = sub, allow_duplicates=True)\n",
    "    y_hit_miss.insert(loc = y_hit_miss.shape[1], column = 'trialnum', \n",
    "                           value = trialnum+1, allow_duplicates=True)\n",
    "    y_hit_miss_train= y_hit_miss_train.append(y_hit_miss, ignore_index=True)\n",
    "    print(y_hit_miss.ctl_miss_hit.value_counts())\n",
    "    print('subject y_shape:', y_hit_miss.shape,\n",
    "         'total y_shape:', y_hit_miss_train.shape)\n",
    "    \n",
    "    # load and concatenate beta maps\n",
    "    betas = image.load_img(img=os.path.join(beta_dir, str(sub), 'TrialContrasts/betas_sub'+str(sub)+'*.nii'),\n",
    "                           wildcards=True)\n",
    "    # vectorize beta maps into a 2D numpy array\n",
    "    sub_trials = hit_miss_masker.fit_transform(betas)\n",
    "    # mask array to filter out trials of no interest\n",
    "    hm_sub_trials = sub_trials[hit_miss_mask]\n",
    "    \n",
    "    # copy filtered vectorized values into set's X data array\n",
    "    X_hit_miss_train[j:(j+hm_sub_trials.shape[0]), :] = hm_sub_trials\n",
    "    j = j + hm_sub_trials.shape[0]\n",
    "    print('number of X filled rows: ', j,\n",
    "          'subject X_shape:', hm_sub_trials.shape,\n",
    "          'total X_shape:', X_hit_miss_train.shape)\n",
    "\n",
    "print('The training data set is built!') \n",
    " \n",
    "\n",
    "# TESTING SET\n",
    "j = 0\n",
    "for sub in hit_miss_test: \n",
    "    print(sub)\n",
    "    # load labels file as pandas dataframe\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_ctl_miss_hit.tsv')\n",
    "    y_hit_miss_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    \n",
    "    # create a boolean mask to filter out trials of no interest\n",
    "    y_hit_miss_ctl_labels = y_hit_miss_ctl['ctl_miss_hit']\n",
    "    hit_miss_mask = y_hit_miss_ctl_labels.isin(['hit', 'missed'])\n",
    "\n",
    "    # apply mask to labels dataframe to keep only hit and missed trials\n",
    "    y_hit_miss = y_hit_miss_ctl[hit_miss_mask]\n",
    "    \n",
    "    # process and append y data to the set's labels dataframe\n",
    "    trialnum = y_hit_miss.index\n",
    "    y_hit_miss.insert(loc = y_hit_miss.shape[1], column = 'dccid', \n",
    "                           value = sub, allow_duplicates=True)\n",
    "    y_hit_miss.insert(loc = y_hit_miss.shape[1], column = 'trialnum', \n",
    "                           value = trialnum+1, allow_duplicates=True)\n",
    "    y_hit_miss_test= y_hit_miss_test.append(y_hit_miss, ignore_index=True)\n",
    "    print(y_hit_miss.ctl_miss_hit.value_counts())\n",
    "    print('subject y_shape:', y_hit_miss.shape,\n",
    "         'total y_shape:', y_hit_miss_test.shape)\n",
    "    \n",
    "    # load and concatenate beta maps\n",
    "    betas = image.load_img(img=os.path.join(beta_dir, str(sub), 'TrialContrasts/betas_sub'+str(sub)+'*.nii'),\n",
    "                           wildcards=True)\n",
    "    # vectorize beta maps into a 2D numpy array\n",
    "    sub_trials = hit_miss_masker.fit_transform(betas)\n",
    "    # mask array to filter out trials of no interest\n",
    "    hm_sub_trials = sub_trials[hit_miss_mask]\n",
    "    \n",
    "    # copy filtered vectorized values into set's X data array\n",
    "    X_hit_miss_test[j:(j+hm_sub_trials.shape[0]), :] = hm_sub_trials\n",
    "    j = j + hm_sub_trials.shape[0]\n",
    "    print('number of X filled rows: ', j,\n",
    "          'subject X_shape:', hm_sub_trials.shape,\n",
    "          'total X_shape:', X_hit_miss_test.shape)\n",
    "\n",
    "print('The testing data set is built!') \n",
    "\n",
    "# 7. rename the labels column from the sets' y dataframe and extract it (to input model)\n",
    "\n",
    "y_hit_miss_train.rename(columns={'ctl_miss_hit': 'miss_hit'}, inplace=True)\n",
    "y_hit_miss_test.rename(columns={'ctl_miss_hit': 'miss_hit'}, inplace=True)\n",
    "\n",
    "y_hit_miss_labels_train = y_hit_miss_train['miss_hit']\n",
    "y_hit_miss_labels_test = y_hit_miss_test['miss_hit']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trials in the training set:  1889 number of trials in the test set:  1965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CORRECT SOURCE VERSUS WRONG SOURCE TRIAL CLASSIFICATION\n",
    "\n",
    "## Keep only the trials of interest (correct source or wrong source, not miss or control)\n",
    "\n",
    "# For each set (training and test), create an empty numpy array to store \n",
    "# concatenated vectorized beta maps (one row per trial; size = trials * voxels).\n",
    "# 1. determine the number of rows needed (sum of trials per participants in set)\n",
    "numrow_train = 0\n",
    "numrow_test = 0\n",
    "for sub in cs_ws_train:\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_ctl_miss_ws_cs.tsv')\n",
    "    y_cs_ws_miss_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    y_cs_ws_miss_ctl_labels = y_cs_ws_miss_ctl['ctl_miss_ws_cs']\n",
    "    cs_ws_mask = y_cs_ws_miss_ctl_labels.isin(['correctsource', 'wrongsource'])\n",
    "    y_cs_ws = y_cs_ws_miss_ctl[cs_ws_mask]\n",
    "    numrow_train = numrow_train + y_cs_ws.shape[0]\n",
    "\n",
    "for sub in cs_ws_test:\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_ctl_miss_ws_cs.tsv')\n",
    "    y_cs_ws_miss_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    y_cs_ws_miss_ctl_labels = y_cs_ws_miss_ctl['ctl_miss_ws_cs']\n",
    "    cs_ws_mask = y_cs_ws_miss_ctl_labels.isin(['correctsource', 'wrongsource'])\n",
    "    y_cs_ws = y_cs_ws_miss_ctl[cs_ws_mask]\n",
    "    numrow_test = numrow_test + y_cs_ws.shape[0]   \n",
    "    \n",
    "print('number of trials in the training set: ', numrow_train,\n",
    "     'number of trials in the test set: ', numrow_test)\n",
    "\n",
    "# 2. determine the number of columns needed (voxels in the vectorized group mask)\n",
    "masker = NiftiMasker(mask_img=grp_mask_cw, standardize=False)\n",
    "numvox = masker.fit_transform(grp_mask_cw).shape[1]\n",
    "\n",
    "\n",
    "# 3. create an empty numpy array to store the data \n",
    "X_cs_ws_train = np.empty(shape=(numrow_train, numvox))\n",
    "X_cs_ws_test = np.empty(shape=(numrow_test, numvox))\n",
    "\n",
    "print(X_cs_ws_train.shape, X_cs_ws_test.shape)\n",
    "\n",
    "# 4. create empty dataframes to store trial labels (one per set)\n",
    "y_cs_ws_train = pd.DataFrame()\n",
    "y_cs_ws_train.insert(loc = 0, column = 'ctl_miss_ws_cs', value = 'TBD', allow_duplicates=True)\n",
    "y_cs_ws_train.insert(loc = 1, column = 'dccid', value = 'TBD', allow_duplicates=True)\n",
    "y_cs_ws_train.insert(loc = 2, column = 'trialnum', value = 'NaN', allow_duplicates=True)\n",
    "\n",
    "y_cs_ws_test = y_cs_ws_train.copy()\n",
    "\n",
    "# 5. create a masker object to vectorize the beta maps; \n",
    "# one map per trial becomes its own row in X_data matrix\n",
    "cs_ws_masker = NiftiMasker(mask_img=grp_mask_cw, standardize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "# 6. Fill the X (beta weights per voxel) and y (trial labels) data matrices\n",
    "\n",
    "# note: nilearn.image.load_img concatenates 3D beta maps in alphabetical order\n",
    "# trial numbers must be PADDED with zeros to preserve their temporal order when alphabetized\n",
    "\n",
    "# TRAINING SET\n",
    "j = 0\n",
    "for sub in cs_ws_train: \n",
    "    print(sub)\n",
    "    # load labels file as pandas dataframe\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_ctl_miss_ws_cs.tsv')\n",
    "    y_cs_ws_miss_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    \n",
    "    # create a boolean mask to filter out trials of no interest\n",
    "    y_cs_ws_miss_ctl_labels = y_cs_ws_miss_ctl['ctl_miss_ws_cs']\n",
    "    cs_ws_mask = y_cs_ws_miss_ctl_labels.isin(['correctsource', 'wrongsource'])\n",
    "\n",
    "    # apply mask to labels dataframe to keep only hit and missed trials\n",
    "    y_cs_ws = y_cs_ws_miss_ctl[cs_ws_mask]\n",
    "    \n",
    "    # process and append y data to the set's labels dataframe\n",
    "    trialnum = y_cs_ws.index\n",
    "    y_cs_ws.insert(loc = y_cs_ws.shape[1], column = 'dccid', \n",
    "                           value = sub, allow_duplicates=True)\n",
    "    y_cs_ws.insert(loc = y_cs_ws.shape[1], column = 'trialnum', \n",
    "                           value = trialnum+1, allow_duplicates=True)\n",
    "    y_cs_ws_train = y_cs_ws_train.append(y_cs_ws, ignore_index=True)\n",
    "    print(y_cs_ws.ctl_miss_ws_cs.value_counts())\n",
    "    print('subject y_shape:', y_cs_ws.shape,\n",
    "         'total y_shape:', y_cs_ws_train.shape)\n",
    "    \n",
    "    # load and concatenate beta maps\n",
    "    betas = image.load_img(img=os.path.join(beta_dir, str(sub), 'TrialContrasts/betas_sub'+str(sub)+'*.nii'),\n",
    "                           wildcards=True)\n",
    "    # vectorize beta maps into a 2D numpy array\n",
    "    sub_trials = cs_ws_masker.fit_transform(betas)\n",
    "    # mask array to filter out trials of no interest\n",
    "    cw_sub_trials = sub_trials[cs_ws_mask]\n",
    "    \n",
    "    # copy filtered vectorized values into set's X data array\n",
    "    X_cs_ws_train[j:(j+cw_sub_trials.shape[0]), :] = cw_sub_trials\n",
    "    j = j + cw_sub_trials.shape[0]\n",
    "    print('number of X filled rows: ', j,\n",
    "          'subject X_shape:', cw_sub_trials.shape,\n",
    "          'total X_shape:', X_cs_ws_train.shape)\n",
    "\n",
    "print('The training data set is built!') \n",
    "\n",
    "\n",
    "# TESTING SET\n",
    "j = 0\n",
    "for sub in cs_ws_test: \n",
    "    print(sub)\n",
    "    # load labels file as pandas dataframe\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_ctl_miss_ws_cs.tsv')\n",
    "    y_cs_ws_miss_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    \n",
    "    # create a boolean mask to filter out trials of no interest\n",
    "    y_cs_ws_miss_ctl_labels = y_cs_ws_miss_ctl['ctl_miss_ws_cs']\n",
    "    cs_ws_mask = y_cs_ws_miss_ctl_labels.isin(['correctsource', 'wrongsource'])\n",
    "\n",
    "    # apply mask to labels dataframe to keep only hit and missed trials\n",
    "    y_cs_ws = y_cs_ws_miss_ctl[cs_ws_mask]\n",
    "    \n",
    "    # process and append y data to the set's labels dataframe\n",
    "    trialnum = y_cs_ws.index\n",
    "    y_cs_ws.insert(loc = y_cs_ws.shape[1], column = 'dccid', \n",
    "                           value = sub, allow_duplicates=True)\n",
    "    y_cs_ws.insert(loc = y_cs_ws.shape[1], column = 'trialnum', \n",
    "                           value = trialnum+1, allow_duplicates=True)\n",
    "    y_cs_ws_test = y_cs_ws_test.append(y_cs_ws, ignore_index=True)\n",
    "    print(y_cs_ws.ctl_miss_ws_cs.value_counts())\n",
    "    print('subject y_shape:', y_cs_ws.shape,\n",
    "         'total y_shape:', y_cs_ws_test.shape)\n",
    "    \n",
    "    # load and concatenate beta maps\n",
    "    betas = image.load_img(img=os.path.join(beta_dir, str(sub), 'TrialContrasts/betas_sub'+str(sub)+'*.nii'),\n",
    "                           wildcards=True)\n",
    "    # vectorize beta maps into a 2D numpy array\n",
    "    sub_trials = cs_ws_masker.fit_transform(betas)\n",
    "    # mask array to filter out trials of no interest\n",
    "    cw_sub_trials = sub_trials[cs_ws_mask]\n",
    "    \n",
    "    # copy filtered vectorized values into set's X data array\n",
    "    X_cs_ws_test[j:(j+cw_sub_trials.shape[0]), :] = cw_sub_trials\n",
    "    j = j + cw_sub_trials.shape[0]\n",
    "    print('number of X filled rows: ', j,\n",
    "          'subject X_shape:', cw_sub_trials.shape,\n",
    "          'total X_shape:', X_cs_ws_test.shape)\n",
    "\n",
    "print('The testing data set is built!') \n",
    "\n",
    "# 7. rename the labels column from the sets' y dataframe and extract it (to input model)\n",
    "\n",
    "y_cs_ws_train.rename(columns={'ctl_miss_ws_cs': 'cs_ws'}, inplace=True)\n",
    "y_cs_ws_test.rename(columns={'ctl_miss_ws_cs': 'cs_ws'}, inplace=True)\n",
    "\n",
    "y_cs_ws_labels_train = y_cs_ws_train['cs_ws']\n",
    "y_cs_ws_labels_test = y_cs_ws_test['cs_ws']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CORRECT SOURCE VERSUS MISS TRIAL CLASSIFICATION\n",
    "\n",
    "## Keep only the trials of interest (correct source or wrong source, not miss or control)\n",
    "\n",
    "# For each set (training and test), create an empty numpy array to store \n",
    "# concatenated vectorized beta maps (one row per trial; size = trials * voxels).\n",
    "# 1. determine the number of rows needed (sum of trials per participants in set)\n",
    "numrow_train = 0\n",
    "numrow_test = 0\n",
    "for sub in cs_miss_train:\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_ctl_miss_ws_cs.tsv')\n",
    "    y_cs_ws_miss_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    y_cs_ws_miss_ctl_labels = y_cs_ws_miss_ctl['ctl_miss_ws_cs']\n",
    "    cs_miss_mask = y_cs_ws_miss_ctl_labels.isin(['correctsource', 'missed'])\n",
    "    y_cs_miss = y_cs_ws_miss_ctl[cs_miss_mask]\n",
    "    numrow_train = numrow_train + y_cs_miss.shape[0]\n",
    "\n",
    "for sub in cs_miss_test:\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_ctl_miss_ws_cs.tsv')\n",
    "    y_cs_ws_miss_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    y_cs_ws_miss_ctl_labels = y_cs_ws_miss_ctl['ctl_miss_ws_cs']\n",
    "    cs_ws_mask = y_cs_ws_miss_ctl_labels.isin(['correctsource', 'wrongsource'])\n",
    "    y_cs_ws = y_cs_ws_miss_ctl[cs_ws_mask]\n",
    "    numrow_test = numrow_test + y_cs_ws.shape[0]   \n",
    "\n",
    "print('number of trials in the training set: ', numrow_train,\n",
    "     'number of trials in the test set: ', numrow_test)\n",
    "\n",
    "# 2. determine the number of columns needed (voxels in the vectorized group mask)\n",
    "masker = NiftiMasker(mask_img=grp_mask_cmiss, standardize=False)\n",
    "numvox = masker.fit_transform(grp_mask_cmiss).shape[1]\n",
    "\n",
    "# 3. create an empty numpy array to store the data \n",
    "X_cs_miss_train = np.empty(shape=(numrow_train, numvox))\n",
    "X_cs_miss_test = np.empty(shape=(numrow_test, numvox))\n",
    "\n",
    "print(X_cs_miss_train.shape, X_cs_miss_test.shape)\n",
    "\n",
    "# 4. create empty dataframes to store trial labels (one per set)\n",
    "y_cs_miss_train = pd.DataFrame()\n",
    "y_cs_miss_train.insert(loc = 0, column = 'ctl_miss_ws_cs', value = 'TBD', allow_duplicates=True)\n",
    "y_cs_miss_train.insert(loc = 1, column = 'dccid', value = 'TBD', allow_duplicates=True)\n",
    "y_cs_miss_train.insert(loc = 2, column = 'trialnum', value = 'NaN', allow_duplicates=True)\n",
    "\n",
    "y_cs_miss_test = y_cs_miss_train.copy()\n",
    "\n",
    "# 5. create a masker object to vectorize the beta maps; \n",
    "# one map per trial becomes its own row in X_data matrix\n",
    "cs_miss_masker = NiftiMasker(mask_img=grp_mask_cmiss, standardize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Fill the X (beta weights per voxel) and y (trial labels) data matrices\n",
    "\n",
    "# note: nilearn.image.load_img concatenates 3D beta maps in alphabetical order\n",
    "# trial numbers must be PADDED with zeros to preserve their temporal order when alphabetized\n",
    "\n",
    "# TRAINING SET\n",
    "j = 0\n",
    "for sub in cs_miss_train: \n",
    "    print(sub)\n",
    "    # load labels file as pandas dataframe\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_ctl_miss_ws_cs.tsv')\n",
    "    y_cs_ws_miss_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    \n",
    "    # create a boolean mask to filter out trials of no interest\n",
    "    y_cs_ws_miss_ctl_labels = y_cs_ws_miss_ctl['ctl_miss_ws_cs']\n",
    "    cs_miss_mask = y_cs_ws_miss_ctl_labels.isin(['correctsource', 'missed'])\n",
    "\n",
    "    # apply mask to labels dataframe to keep only hit and missed trials\n",
    "    y_cs_miss = y_cs_ws_miss_ctl[cs_miss_mask]\n",
    "    \n",
    "    # process and append y data to the set's labels dataframe\n",
    "    trialnum = y_cs_miss.index\n",
    "    y_cs_miss.insert(loc = y_cs_miss.shape[1], column = 'dccid', \n",
    "                           value = sub, allow_duplicates=True)\n",
    "    y_cs_miss.insert(loc = y_cs_miss.shape[1], column = 'trialnum', \n",
    "                           value = trialnum+1, allow_duplicates=True)\n",
    "    y_cs_miss_train = y_cs_miss_train.append(y_cs_miss, ignore_index=True)\n",
    "    print(y_cs_miss.ctl_miss_ws_cs.value_counts())\n",
    "    print('subject y_shape:', y_cs_miss.shape,\n",
    "         'total y_shape:', y_cs_miss_train.shape)\n",
    "    \n",
    "    # load and concatenate beta maps\n",
    "    betas = image.load_img(img=os.path.join(beta_dir, str(sub), 'TrialContrasts/betas_sub'+str(sub)+'*.nii'),\n",
    "                           wildcards=True)\n",
    "    # vectorize beta maps into a 2D numpy array\n",
    "    sub_trials = cs_miss_masker.fit_transform(betas)\n",
    "    # mask array to filter out trials of no interest\n",
    "    cm_sub_trials = sub_trials[cs_miss_mask]\n",
    "    \n",
    "    # copy filtered vectorized values into set's X data array\n",
    "    X_cs_miss_train[j:(j+cm_sub_trials.shape[0]), :] = cm_sub_trials\n",
    "    j = j + cm_sub_trials.shape[0]\n",
    "    print('number of X filled rows: ', j,\n",
    "          'subject X_shape:', cm_sub_trials.shape,\n",
    "          'total X_shape:', X_cs_miss_train.shape)\n",
    "\n",
    "print('The training data set is built!') \n",
    "\n",
    "    \n",
    "# TESTING SET\n",
    "j = 0\n",
    "for sub in cs_miss_test: \n",
    "    print(sub)\n",
    "    # load labels file as pandas dataframe\n",
    "    labels_file = os.path.join(label_dir, 'sub-'+str(sub)+'_ctl_miss_ws_cs.tsv')\n",
    "    y_cs_ws_miss_ctl = pd.read_csv(labels_file, sep='\\t')\n",
    "    \n",
    "    # create a boolean mask to filter out trials of no interest\n",
    "    y_cs_ws_miss_ctl_labels = y_cs_ws_miss_ctl['ctl_miss_ws_cs']\n",
    "    cs_miss_mask = y_cs_ws_miss_ctl_labels.isin(['correctsource', 'missed'])\n",
    "\n",
    "    # apply mask to labels dataframe to keep only hit and missed trials\n",
    "    y_cs_miss = y_cs_ws_miss_ctl[cs_miss_mask]\n",
    "    \n",
    "    # process and append y data to the set's labels dataframe\n",
    "    trialnum = y_cs_miss.index\n",
    "    y_cs_miss.insert(loc = y_cs_miss.shape[1], column = 'dccid', \n",
    "                           value = sub, allow_duplicates=True)\n",
    "    y_cs_miss.insert(loc = y_cs_miss.shape[1], column = 'trialnum', \n",
    "                           value = trialnum+1, allow_duplicates=True)\n",
    "    y_cs_miss_test = y_cs_miss_test.append(y_cs_miss, ignore_index=True)\n",
    "    print(y_cs_miss.ctl_miss_ws_cs.value_counts())\n",
    "    print('subject y_shape:', y_cs_miss.shape,\n",
    "         'total y_shape:', y_cs_miss_test.shape)\n",
    "    \n",
    "    # load and concatenate beta maps\n",
    "    betas = image.load_img(img=os.path.join(beta_dir, str(sub), 'TrialContrasts/betas_sub'+str(sub)+'*.nii'),\n",
    "                           wildcards=True)\n",
    "    # vectorize beta maps into a 2D numpy array\n",
    "    sub_trials = cs_miss_masker.fit_transform(betas)\n",
    "    # mask array to filter out trials of no interest\n",
    "    cm_sub_trials = sub_trials[cs_miss_mask]\n",
    "    \n",
    "    # copy filtered vectorized values into set's X data array\n",
    "    X_cs_miss_test[j:(j+cm_sub_trials.shape[0]), :] = cm_sub_trials\n",
    "    j = j + cm_sub_trials.shape[0]\n",
    "    print('number of X filled rows: ', j,\n",
    "          'subject X_shape:', cm_sub_trials.shape,\n",
    "          'total X_shape:', X_cs_miss_test.shape)\n",
    "\n",
    "print('The testing data set is built!') \n",
    "\n",
    "# 7. rename the labels column from the sets' y dataframe and extract it (to input model)\n",
    "\n",
    "y_cs_miss_train.rename(columns={'ctl_miss_ws_cs': 'cs_miss'}, inplace=True)\n",
    "y_cs_miss_test.rename(columns={'ctl_miss_ws_cs': 'cs_miss'}, inplace=True)\n",
    "\n",
    "y_cs_miss_labels_train = y_cs_miss_train['cs_miss']\n",
    "y_cs_miss_labels_test = y_cs_miss_test['cs_miss']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. Create and trian the Support Vector Classififer model!!\n",
    "\n",
    "Support documentation:\n",
    "https://nilearn.github.io/decoding/estimator_choice.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm\n",
    "Note: LinearSVC scales better than SVC to large datasets, equivalent to SVC with linear kernel\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "\n",
    "Neurolibre tutorial (MAIN 2018):\n",
    "https://brainhack101.github.io/introML-book/01/MAIN_tutorial_machine_learning_with_nilearn\n",
    "\n",
    "Example with Haxby dataset (within subject):\n",
    "https://nilearn.github.io/auto_examples/plot_decoding_tutorial.html#retrieve-and-load-the-fmri-data-from-the-haxby-study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# Data to input the Support Vector Machine model for different classifications: \n",
    "\n",
    "# ENCODING vs CONTROL condition: \n",
    "# Training: X_enc_ctl_train, y_enco_ctl_labels_train\n",
    "# Testing: X_enc_ctl_test, y_enco_ctl_labels_test\n",
    "\n",
    "# HIT vs MISS trials: \n",
    "# Training: X_hit_miss_train, y_hit_miss_labels_train\n",
    "# Testing: X_hit_miss_test, y_hit_miss_labels_test\n",
    "\n",
    "# CORRECT SOURCE vs WRONG SOURCE trials:\n",
    "# Training: X_cs_ws_train, y_cs_ws_labels_train\n",
    "# Testing: X_cs_ws_test, y_cs_ws_labels_test\n",
    "\n",
    "# CORRECT SOURCE vs MISS trials: \n",
    "# Training: X_cs_miss_train, y_cs_miss_labels_train\n",
    "# Testing: X_cs_miss_test, y_cs_miss_labels_test\n",
    "\n",
    "X_train = X_enc_ctl_train\n",
    "y_train = y_enco_ctl_labels_train\n",
    "X_test = X_enc_ctl_test\n",
    "y_test = y_enco_ctl_labels_test\n",
    "\n",
    "# initialise the SVC model\n",
    "# Note that class_weight gives equivalent influence to different categories\n",
    "# important if number of trials differs per condition\n",
    "#trial_svc = SVC(kernel='linear', class_weight='balanced') #define the model\n",
    "trial_svc = LinearSVC(class_weight='balanced') #define the model\n",
    "\n",
    "print(trial_svc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a89e41dc2742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m y_pred = cross_val_predict(trial_svc, X_train, y_train,\n\u001b[0;32m----> 4\u001b[0;31m                            groups=y_train, cv=7)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m acc = cross_val_score(trial_svc, X_train, y_train,\n",
      "\u001b[0;32m/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    775\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    776\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 777\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/may19_py36/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up 10-fold cross-validation to evaluate the model's performance over the training set\n",
    "# predict\n",
    "y_pred = cross_val_predict(trial_svc, X_train, y_train,\n",
    "                           groups=y_train, cv=7)\n",
    "# scores\n",
    "acc = cross_val_score(trial_svc, X_train, y_train,\n",
    "                     groups=y_train, cv=7)\n",
    "\n",
    "#Look at accuracy of prediction for each fold of the cross-validation\n",
    "for i in range(7):\n",
    "    print('Fold %s -- Acc = %s'%(i, acc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#look at the overall accuracy of the model (over training data set)\n",
    "\n",
    "overall_acc = accuracy_score(y_pred = y_pred, y_true = y_train)\n",
    "overall_cr = classification_report(y_pred = y_pred, y_true = y_train)\n",
    "overall_cm = confusion_matrix(y_pred = y_pred, y_true = y_train)\n",
    "print('Accuracy: ',overall_acc)\n",
    "print(overall_cr)\n",
    "\n",
    "thresh = overall_cm.max() / 2\n",
    "cmdf = pd.DataFrame(overall_cm, index = ['Control','Encoding'], columns = ['Control','Encoding'])\n",
    "sns.heatmap(cmdf, cmap='RdBu_r')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "for i, j in itertools.product(range(overall_cm.shape[0]), range(overall_cm.shape[1])):\n",
    "        plt.text(j+0.5, i+0.5, format(overall_cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
